{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 텐서플로우를 구성하는 가장 기초적인 데이터 단위\n",
    " - n 차원 배열의 집합 또는 n 차원 배열을 의미\n",
    " - rank: 텐서의 차원\n",
    " - 텐서의 표현은 `numpy` 배열을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3. # a rank 0 tensor; a scalar with shape []\n",
    "[1., 2., 3.] # a rank 1 tensor; a vector with shape [3],\n",
    "[[1., 2., 3.], [4., 5., 6.]] # a rank 2 tensor; a matrix with shape [2, 3],\n",
    "[[[1., 2., 3.]], [[7., 8., 9.]]] # a rank 3 tensor with shape [2, 1, 3]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TensorFlow programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 1) 연산 그래프(computational graph) 정의\n",
    "  - 연산그래프는 텐서플로우 작업을 순차적으로 정의(표현)한 것으로 노드와 에지를 갖는 그래프 형태를 갖음 \n",
    "  - 연산그래프의 노드에는 텐서를 입력값으로 받아 연산하는 작업들이 위치 : `tf.Operation`\n",
    "  - 연산그래프의 에지에는 노드에 정의된 연산간에 주고 받는 데이터 들을 표현(텐서들이 그래프 상에서 흐름.) `tf.Tensor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 2) 연산 그래프를 실행\n",
    "  - 연산그래프의 실행은 `tf.Session` 객체,텐서플로우가 실행되는 환경을 만들어서 진행됨\n",
    "  - 연산그래프의 작업을 CPU, GPU에 배정하고 실행을 위한 메서드를 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [default 그래프에 정의하기]\n",
    " - 3개의 노드(2개: constant op, 1개 matmul op)\n",
    " - 특정 그래프 객체에 명시적으로 연산을 정의하지 않는한 모든 연산은 전역 default 그래프에 정의됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "mat_a = tf.constant([[3.0, 3.0]], dtype=tf.float32)\n",
    "mat_b = tf.constant([[2.0],[2.0]], dtype=tf.float32)\n",
    "product = tf.matmul(mat_a, mat_b)\n",
    "\n",
    "print(tf.get_default_graph() is product.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [특정 그래프에 연산 정의하기]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "g_1 = tf.Graph()\n",
    "with g_1.as_default():\n",
    "    mat_a = tf.constant([[3.0, 3.0]], dtype=tf.float32)\n",
    "    mat_b = tf.constant([[2.0],[2.0]], dtype=tf.float32)\n",
    "    product = tf.matmul(mat_a, mat_b)\n",
    "    print(product.graph is g_1)\n",
    "\n",
    "g_2 = tf.Graph()\n",
    "with g_2.as_default():\n",
    "    mat_a = tf.constant([[3.0, 3.0]], dtype=tf.float32)\n",
    "    mat_b = tf.constant([[2.0],[2.0]], dtype=tf.float32)\n",
    "    product = tf.matmul(mat_a, mat_b)\n",
    "    print(product.graph is g_2)\n",
    "# with tf.Graph().as_default() as g_2:\n",
    "#     mat_a = tf.constant([[3.0, 3.0]], dtype=tf.float32)\n",
    "#     mat_b = tf.constant([[2.0],[2.0]], dtype=tf.float32)\n",
    "#     product = tf.matmul(mat_a, mat_b)\n",
    "#     print(product.graph is g_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [그래프 실행하기]\n",
    " - session 객체의 run 매서드 호출\n",
    " - default 그래프에 정의한 3개의 작업이 실행 (graph=None)\n",
    " - 사용한 session 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session(graph=g_2)\n",
    "print(sess.run(product))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - session 컨텍스트 매니저 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g_2) as sess:\n",
    "    print(sess.run(product))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 연산 자원 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g_2) as sess:\n",
    "    with tf.device('/gpu:0'):\n",
    "        print(sess.run(product))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TensorFlow tf.constant, tf.Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 연산 그래프에 정의된 연산을 수행하기 위해 필요한 데이터 값을 입력 위한 수단 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3-1. tf.constant\n",
    " - 상수 텐서를 생성하는 작업으로, `tf.constant` 연산 정의시 제공한 초기값을 갖는 텐서를 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3-2. tf.Variable\n",
    " - 텐서플로우 프로그램에서 연산의 결과가 공유되고, 상태를 유지해야하는 경우 사용 \n",
    "   - ex) 학습을 진행하면서 모델의 파라미터가 업데이트 되야하므로 모델의 파라미터를 변수로 표현\n",
    " - 변수 연산을 정의하기 위해 텐서를 초기값으로 부여, 초기값으로 제공한 텐서로 변수 type과 shape이 결정됨\n",
    " - 변수 연산이 정의되면 타입과 변수 type과 shape은 고정됨, 변수 값인 텐서를 assign 메서드로 변경\n",
    " - 연산을 실행하기 전, 그래프 상에 정의된 변수를 명시적으로 초기화하는 작업 필요\n",
    "   - 초기화 연산을 실행(`tf.global_variable_initializer()`), 변수 값이 저장된 파일에서 복구, `assign` 메서드 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "state = tf.Variable(0, name=\"counter\")\n",
    "one = tf.constant(1)\n",
    "new_value = tf.add(state, one)\n",
    "update = tf.assign(state, new_value)\n",
    "init_op = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(state))\n",
    "    for _ in range(3):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### [변수의 저장과 복구]\n",
    "  - 변수를 이름과 텐서 값을 매핑해놓은 바이너리 파일(`.ckpt`)에 저장 가능\n",
    "  - `tf.train.Saver()` 객체를 이용하여 그래프 전체 변수와 지정된 리스트 변수를 저장하고 복구\n",
    "  - 저장될 때 사용되는 변수 명은 `Variable.name`이 기본 값\n",
    "  - `tf.train.Saver()` 객체에 딕셔너리를 저장할 이름(key), 저장할 값(value)로 전달하여 저장시 사용할 이름을 변경하거나 변수를 선택적으로 저장 가능\n",
    "    - ex) `tf.train.Saver({\"saved_v\":v})`\n",
    "  - 전체 변수를 파일에서 복구 시 변수 초기화가 필요 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: ./tmp/ckpt/model.ckpt\n",
      "tensor_name:  counter\n",
      "0\n",
      "tensor_name:  variable/v1\n",
      "[1. 1. 1.]\n",
      "tensor_name:  variable/v2\n",
      "[-1. -1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "# Create some variables.\n",
    "import tensorflow as tf\n",
    "import os, shutil\n",
    "\n",
    "with tf.variable_scope(\"variable\", reuse=tf.AUTO_REUSE):\n",
    "    v1 = tf.get_variable(\"v1\", shape=[3], initializer = tf.zeros_initializer)\n",
    "    v2 = tf.get_variable(\"v2\", shape=[5], initializer = tf.zeros_initializer)\n",
    "\n",
    "inc_v1 = v1.assign(v1+1)\n",
    "dec_v2 = v2.assign(v2-1)\n",
    "\n",
    "# Add an op to initialize the variables.\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, initialize the variables, do some work, and save the\n",
    "# variables to disk.\n",
    "with tf.Session() as sess:\n",
    "  sess.run(init_op)\n",
    "  # Do some work with the model.\n",
    "  inc_v1.op.run()\n",
    "  dec_v2.op.run()\n",
    "  # Save the variables to disk.\n",
    "  shutil.rmtree(\"./tmp/ckpt\")\n",
    "  os.mkdir(\"./tmp/ckpt\")\n",
    "  save_path = saver.save(sess, \"./tmp/ckpt/model.ckpt\")\n",
    "  print(\"Model saved in path: %s\" % save_path)\n",
    "    \n",
    "    \n",
    "from tensorflow.python.tools import inspect_checkpoint as chkp\n",
    "chkp.print_tensors_in_checkpoint_file(save_path, tensor_name='',  all_tensors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt/model.ckpt\n",
      "Model restored.\n",
      "v1 : [1. 1. 1.]\n",
      "v2 : [-1. -1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Create some variables.\n",
    "with tf.variable_scope(\"variable\", reuse=tf.AUTO_REUSE):\n",
    "    v1 = tf.get_variable(\"v1\", shape=[3])\n",
    "    v2 = tf.get_variable(\"v2\", shape=[5])\n",
    "    \n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "  # Restore variables from disk.\n",
    "  saver.restore(sess, \"./tmp/ckpt/model.ckpt\")\n",
    "  print(\"Model restored.\")\n",
    "  # Check the values of the variables\n",
    "  print(\"v1 : %s\" % v1.eval())\n",
    "  print(\"v2 : %s\" % v2.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### - tf.get_variable()\n",
    "  - 공유 변수를 손쉽게 구현하기 위해 `tf.Variable`를 직접호출하지 않고 생성된 변수를 가져오거나 존재하지 않을 시 새롭게 생성\n",
    "     - ex) 매우 깊은 층을 갖는 심층심경망 네트워크 구현시 각 층마다 변수를 정의하는 데 따른 불편함을 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"layer1\", reuse=tf.AUTO_REUSE):\n",
    "     weight = tf.get_variable(\n",
    "            \"weight\", \n",
    "            [1, 2, 3], \n",
    "            dtype=tf.int32, \n",
    "            initializer=tf.zeros_initializer\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fetches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 그래프 상에 정의된 작업 하나 이상의 작업 결과 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([21.], dtype=float32), array([7.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.constant([3.0])\n",
    "input2 = tf.constant([2.0])\n",
    "input3 = tf.constant([5.0])\n",
    "intermed = tf.add(input2, input3)\n",
    "mul = tf.multiply(input1, intermed)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  result = sess.run([mul, intermed])\n",
    "  print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 실행 시점에 연산 그래프 상으로 텐서 값을 제공하는 매커니즘\n",
    " - tf.placeholder를 이용 텐서가 입력될 공간을 확보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.6050478  1.3077159  1.9545476  0.63395727]\n",
      " [0.9608991  0.8180288  1.138182   0.8393545 ]\n",
      " [0.93346936 0.44573757 1.4754423  0.7266189 ]\n",
      " [1.612025   1.0525079  1.6330013  0.78841984]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x1 = tf.placeholder(tf.float32, shape=(4, 4), name='input1')\n",
    "x2 = tf.placeholder(tf.float32, shape=(4, 4), name='input2')\n",
    "y = tf.matmul(x1, x2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#   print(sess.run(y))  # ERROR: will fail because x was not fed.\n",
    "  arr = np.random.rand(4, 4)\n",
    "  print(sess.run(y, feed_dict={x1: arr, x2:arr}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization : 텐서보드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 텐서플로우가 제공하는 텐서보드를 활용하여 연산 그래프를 시각화\n",
    " - 그래프 실행 후 연산 결과 시각화\n",
    " - `tf.summary.FileWriter()` 객체에 연산 그래프와 연산 결과 값을 저장 후 텐서보드로 시각화   \n",
    " - 벡터: `tf.summary.histogram()`, 스칼라: `tf.summary.scalar()`로 시각화할 연산 값 설정\n",
    " - 텐서보드 실행 => `tensorboard --logdir==\"./logs/xor_log\"` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.71215135 [array([[-0.12497693,  0.7248027 ],\n",
      "       [ 2.080678  ,  0.7145885 ]], dtype=float32), array([[ 0.0093445 ],\n",
      "       [-0.40808776]], dtype=float32)]\n",
      "100 0.679781 [array([[1.3409436 , 0.12809893],\n",
      "       [3.203717  , 0.18864527]], dtype=float32), array([[ 0.43088317],\n",
      "       [-0.34206858]], dtype=float32)]\n",
      "200 0.5770617 [array([[ 3.1298156, -1.0282263],\n",
      "       [ 4.968024 ,  1.4701347]], dtype=float32), array([[ 1.8076667 ],\n",
      "       [-0.98076457]], dtype=float32)]\n",
      "300 0.4501462 [array([[ 4.2024913, -2.7989244],\n",
      "       [ 6.3008695,  3.6694086]], dtype=float32), array([[ 2.959731 ],\n",
      "       [-2.1323946]], dtype=float32)]\n",
      "400 0.39884686 [array([[ 4.7286286, -3.7018058],\n",
      "       [ 7.19109  ,  4.9015245]], dtype=float32), array([[ 3.6619143],\n",
      "       [-2.9954233]], dtype=float32)]\n",
      "500 0.37843448 [array([[ 5.037748, -4.208903],\n",
      "       [ 7.831789,  5.696274]], dtype=float32), array([[ 4.1242127],\n",
      "       [-3.576949 ]], dtype=float32)]\n",
      "600 0.36834592 [array([[ 5.251919 , -4.5470395],\n",
      "       [ 8.331124 ,  6.2770977]], dtype=float32), array([[ 4.469223 ],\n",
      "       [-4.0079546]], dtype=float32)]\n",
      "700 0.36254984 [array([[ 5.4150248, -4.796846 ],\n",
      "       [ 8.7413645,  6.735529 ]], dtype=float32), array([[ 4.7464657],\n",
      "       [-4.3507147]], dtype=float32)]\n",
      "800 0.35887173 [array([[ 5.546643, -4.993485],\n",
      "       [ 9.090575,  7.115328]], dtype=float32), array([[ 4.9797034],\n",
      "       [-4.6362042]], dtype=float32)]\n",
      "900 0.35637045 [array([[ 5.6570244, -5.154993 ],\n",
      "       [ 9.395425 ,  7.4404783]], dtype=float32), array([[ 5.18206  ],\n",
      "       [-4.8816805]], dtype=float32)]\n",
      "1000 0.35458097 [array([[ 5.752168 , -5.2917356],\n",
      "       [ 9.666594 ,  7.7254925]], dtype=float32), array([[ 5.3615403],\n",
      "       [-5.097672 ]], dtype=float32)]\n",
      "1100 0.35325038 [array([[ 5.8358707, -5.4101586],\n",
      "       [ 9.911339 ,  7.9798107]], dtype=float32), array([[ 5.5233865],\n",
      "       [-5.291057 ]], dtype=float32)]\n",
      "1200 0.35223022 [array([[ 5.9106827, -5.514542 ],\n",
      "       [10.134821 ,  8.2099085]], dtype=float32), array([[ 5.671221 ],\n",
      "       [-5.4665756]], dtype=float32)]\n",
      "1300 0.3514287 [array([[ 5.978398 , -5.60785  ],\n",
      "       [10.3408165,  8.42043  ]], dtype=float32), array([[ 5.807657 ],\n",
      "       [-5.6276264]], dtype=float32)]\n",
      "1400 0.35078597 [array([[ 6.040322 , -5.6922174],\n",
      "       [10.532207 ,  8.614814 ]], dtype=float32), array([[ 5.934645 ],\n",
      "       [-5.7767353]], dtype=float32)]\n",
      "1500 0.35026187 [array([[ 6.097439 , -5.7692347],\n",
      "       [10.711234 ,  8.7956705]], dtype=float32), array([[ 6.053674 ],\n",
      "       [-5.9158263]], dtype=float32)]\n",
      "1600 0.34982842 [array([[ 6.150502, -5.840109],\n",
      "       [10.879641,  8.965037]], dtype=float32), array([[ 6.1659126],\n",
      "       [-6.046398 ]], dtype=float32)]\n",
      "1700 0.349465 [array([[ 6.2001057, -5.90578  ],\n",
      "       [11.038839 ,  9.124538 ]], dtype=float32), array([[ 6.272296 ],\n",
      "       [-6.1696467]], dtype=float32)]\n",
      "1800 0.34915757 [array([[ 6.2467327, -5.9669976],\n",
      "       [11.190029 ,  9.275477 ]], dtype=float32), array([[ 6.3735766],\n",
      "       [-6.2865353]], dtype=float32)]\n",
      "1900 0.34889454 [array([[ 6.2907553, -6.024365 ],\n",
      "       [11.334123 ,  9.41893  ]], dtype=float32), array([[ 6.4703827],\n",
      "       [-6.3978586]], dtype=float32)]\n",
      "2000 0.34866795 [array([[ 6.3325057, -6.0783677],\n",
      "       [11.472006 ,  9.555777 ]], dtype=float32), array([[ 6.5632315],\n",
      "       [-6.5042677]], dtype=float32)]\n",
      "2100 0.348471 [array([[ 6.372234, -6.129422],\n",
      "       [11.604269,  9.686765]], dtype=float32), array([[ 6.6525617],\n",
      "       [-6.6063194]], dtype=float32)]\n",
      "2200 0.34829903 [array([[ 6.41016 , -6.177851],\n",
      "       [11.7315  ,  9.812519]], dtype=float32), array([[ 6.738743 ],\n",
      "       [-6.7044783]], dtype=float32)]\n",
      "2300 0.3481475 [array([[ 6.4464893, -6.2239475],\n",
      "       [11.85425  ,  9.933589 ]], dtype=float32), array([[ 6.822094],\n",
      "       [-6.799144]], dtype=float32)]\n",
      "2400 0.34801382 [array([[ 6.4813833, -6.267963 ],\n",
      "       [11.972934 , 10.05042  ]], dtype=float32), array([[ 6.9028935],\n",
      "       [-6.8906612]], dtype=float32)]\n",
      "2500 0.34789476 [array([[ 6.5149684, -6.3100863],\n",
      "       [12.0878935, 10.163426 ]], dtype=float32), array([[ 6.98138 ],\n",
      "       [-6.979327]], dtype=float32)]\n",
      "2600 0.34778845 [array([[ 6.547364 , -6.3505273],\n",
      "       [12.199457 , 10.272951 ]], dtype=float32), array([[ 7.05776  ],\n",
      "       [-7.0654035]], dtype=float32)]\n",
      "2700 0.34769338 [array([[ 6.5786777, -6.389405 ],\n",
      "       [12.307919 , 10.379311 ]], dtype=float32), array([[ 7.132219],\n",
      "       [-7.149116]], dtype=float32)]\n",
      "2800 0.3476076 [array([[ 6.6090007, -6.426881 ],\n",
      "       [12.413539 , 10.482764 ]], dtype=float32), array([[ 7.2049227],\n",
      "       [-7.2306714]], dtype=float32)]\n",
      "2900 0.34753045 [array([[ 6.6384144, -6.4630733],\n",
      "       [12.516533 , 10.583567 ]], dtype=float32), array([[ 7.2760158],\n",
      "       [-7.310247 ]], dtype=float32)]\n",
      "3000 0.34746027 [array([[ 6.6669917, -6.4980893],\n",
      "       [12.617119 , 10.681913 ]], dtype=float32), array([[ 7.3456283],\n",
      "       [-7.388002 ]], dtype=float32)]\n",
      "3100 0.3473968 [array([[ 6.694795 , -6.5319734],\n",
      "       [12.71548  , 10.7779875]], dtype=float32), array([[ 7.413876 ],\n",
      "       [-7.4640784]], dtype=float32)]\n",
      "3200 0.34733906 [array([[ 6.7219095, -6.5649137],\n",
      "       [12.811855 , 10.872002 ]], dtype=float32), array([[ 7.480862 ],\n",
      "       [-7.5386057]], dtype=float32)]\n",
      "3300 0.34728628 [array([[ 6.7483897, -6.5969167],\n",
      "       [12.906426 , 10.964068 ]], dtype=float32), array([[ 7.5466876],\n",
      "       [-7.6116977]], dtype=float32)]\n",
      "3400 0.3472377 [array([[ 6.7742543, -6.628006 ],\n",
      "       [12.999216 , 11.054353 ]], dtype=float32), array([[ 7.611436 ],\n",
      "       [-7.6834617]], dtype=float32)]\n",
      "3500 0.3471933 [array([[ 6.799548 , -6.658282 ],\n",
      "       [13.0903425, 11.14296  ]], dtype=float32), array([[ 7.675182 ],\n",
      "       [-7.7539916]], dtype=float32)]\n",
      "3600 0.34715253 [array([[ 6.824309, -6.687805],\n",
      "       [13.179926, 11.230034]], dtype=float32), array([[ 7.7379966],\n",
      "       [-7.8233714]], dtype=float32)]\n",
      "3700 0.34711504 [array([[ 6.8485727, -6.7167425],\n",
      "       [13.26807  , 11.315677 ]], dtype=float32), array([[ 7.7999473],\n",
      "       [-7.891686 ]], dtype=float32)]\n",
      "3800 0.3470804 [array([[ 6.872368 , -6.7450056],\n",
      "       [13.354868 , 11.399958 ]], dtype=float32), array([[ 7.861092 ],\n",
      "       [-7.9590044]], dtype=float32)]\n",
      "3900 0.34704834 [array([[ 6.8957253, -6.772633 ],\n",
      "       [13.440403 , 11.482968 ]], dtype=float32), array([[ 7.921482],\n",
      "       [-8.02539 ]], dtype=float32)]\n",
      "4000 0.34701872 [array([[ 6.918669 , -6.7996597],\n",
      "       [13.524754 , 11.564787 ]], dtype=float32), array([[ 7.981169],\n",
      "       [-8.090898]], dtype=float32)]\n",
      "4100 0.34699124 [array([[ 6.941226 , -6.8261156],\n",
      "       [13.60799  , 11.64549  ]], dtype=float32), array([[ 8.040201],\n",
      "       [-8.155588]], dtype=float32)]\n",
      "4200 0.34696567 [array([[ 6.963418 , -6.852046 ],\n",
      "       [13.6901865, 11.725142 ]], dtype=float32), array([[ 8.098617],\n",
      "       [-8.219512]], dtype=float32)]\n",
      "4300 0.34694213 [array([[ 6.985264 , -6.8774652],\n",
      "       [13.771402 , 11.803811 ]], dtype=float32), array([[ 8.156457],\n",
      "       [-8.282718]], dtype=float32)]\n",
      "4400 0.34692007 [array([[ 7.006783, -6.902414],\n",
      "       [13.851697, 11.881552]], dtype=float32), array([[ 8.213762],\n",
      "       [-8.345254]], dtype=float32)]\n",
      "4500 0.34689948 [array([[ 7.0279927, -6.926902 ],\n",
      "       [13.931122 , 11.958413 ]], dtype=float32), array([[ 8.270563],\n",
      "       [-8.407155]], dtype=float32)]\n",
      "4600 0.3468805 [array([[ 7.04891  , -6.9509645],\n",
      "       [14.009711 , 12.034453 ]], dtype=float32), array([[ 8.326894],\n",
      "       [-8.468465]], dtype=float32)]\n",
      "4700 0.3468625 [array([[ 7.0695477, -6.974624 ],\n",
      "       [14.087544 , 12.109747 ]], dtype=float32), array([[ 8.382778],\n",
      "       [-8.52921 ]], dtype=float32)]\n",
      "4800 0.34684598 [array([[ 7.089928 , -6.9981904],\n",
      "       [14.164624 , 12.184378 ]], dtype=float32), array([[ 8.438252],\n",
      "       [-8.589437]], dtype=float32)]\n",
      "4900 0.3468303 [array([[ 7.1100564, -7.02143  ],\n",
      "       [14.241011 , 12.2583065]], dtype=float32), array([[ 8.493337],\n",
      "       [-8.649169]], dtype=float32)]\n",
      "5000 0.34681588 [array([[ 7.129944, -7.04433 ],\n",
      "       [14.316749, 12.331576]], dtype=float32), array([[ 8.548049],\n",
      "       [-8.708426]], dtype=float32)]\n",
      "5100 0.34680218 [array([[ 7.149602 , -7.0669065],\n",
      "       [14.391853 , 12.404228 ]], dtype=float32), array([[ 8.602422],\n",
      "       [-8.767248]], dtype=float32)]\n",
      "5200 0.34678936 [array([[ 7.1690435, -7.0891576],\n",
      "       [14.466373 , 12.476295 ]], dtype=float32), array([[ 8.656462],\n",
      "       [-8.825642]], dtype=float32)]\n",
      "5300 0.34677717 [array([[ 7.188274, -7.111112],\n",
      "       [14.540336, 12.5478  ]], dtype=float32), array([[ 8.710199],\n",
      "       [-8.883642]], dtype=float32)]\n",
      "5400 0.34676602 [array([[ 7.207305 , -7.1327806],\n",
      "       [14.613765 , 12.618778 ]], dtype=float32), array([[ 8.763645],\n",
      "       [-8.941267]], dtype=float32)]\n",
      "5500 0.3467554 [array([[ 7.2261467, -7.1541696],\n",
      "       [14.686689 , 12.689258 ]], dtype=float32), array([[ 8.816825],\n",
      "       [-8.998542]], dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600 0.34674537 [array([[ 7.2448053, -7.175319 ],\n",
      "       [14.759137 , 12.75925  ]], dtype=float32), array([[ 8.86975 ],\n",
      "       [-9.055481]], dtype=float32)]\n",
      "5700 0.346736 [array([[ 7.263286 , -7.1961985],\n",
      "       [14.831116 , 12.828791 ]], dtype=float32), array([[ 8.922431],\n",
      "       [-9.112097]], dtype=float32)]\n",
      "5800 0.34672704 [array([[ 7.281598 , -7.2168264],\n",
      "       [14.902658 , 12.897907 ]], dtype=float32), array([[ 8.974886],\n",
      "       [-9.168415]], dtype=float32)]\n",
      "5900 0.34671885 [array([[ 7.2997465, -7.2372327],\n",
      "       [14.973797 , 12.966601 ]], dtype=float32), array([[ 9.027128],\n",
      "       [-9.224444]], dtype=float32)]\n",
      "6000 0.34671116 [array([[ 7.3177404, -7.257412 ],\n",
      "       [15.044515 , 13.034901 ]], dtype=float32), array([[ 9.079168],\n",
      "       [-9.280198]], dtype=float32)]\n",
      "6100 0.34670377 [array([[ 7.335584, -7.277367],\n",
      "       [15.114866, 13.10283 ]], dtype=float32), array([[ 9.131018],\n",
      "       [-9.335696]], dtype=float32)]\n",
      "6200 0.34669688 [array([[ 7.3532825, -7.297133 ],\n",
      "       [15.184843 , 13.1704   ]], dtype=float32), array([[ 9.182689],\n",
      "       [-9.390947]], dtype=float32)]\n",
      "6300 0.3466903 [array([[ 7.3708405, -7.316677 ],\n",
      "       [15.254485 , 13.237632 ]], dtype=float32), array([[ 9.23419 ],\n",
      "       [-9.445967]], dtype=float32)]\n",
      "6400 0.346684 [array([[ 7.3882627, -7.336035 ],\n",
      "       [15.323814 , 13.304539 ]], dtype=float32), array([[ 9.285534],\n",
      "       [-9.500766]], dtype=float32)]\n",
      "6500 0.34667808 [array([[ 7.405559 , -7.3552217],\n",
      "       [15.392822 , 13.371141 ]], dtype=float32), array([[ 9.336731],\n",
      "       [-9.55537 ]], dtype=float32)]\n",
      "6600 0.34667283 [array([[ 7.4227276, -7.3742123],\n",
      "       [15.461472 , 13.437448 ]], dtype=float32), array([[ 9.387788],\n",
      "       [-9.609776]], dtype=float32)]\n",
      "6700 0.3466676 [array([[ 7.439776 , -7.3930364],\n",
      "       [15.529912 , 13.503462 ]], dtype=float32), array([[ 9.438716],\n",
      "       [-9.663986]], dtype=float32)]\n",
      "6800 0.34666267 [array([[ 7.4567056, -7.411676 ],\n",
      "       [15.598041 , 13.569212 ]], dtype=float32), array([[ 9.489511],\n",
      "       [-9.718018]], dtype=float32)]\n",
      "6900 0.34665802 [array([[ 7.473518 , -7.4301586],\n",
      "       [15.665898 , 13.634697 ]], dtype=float32), array([[ 9.540198],\n",
      "       [-9.771881]], dtype=float32)]\n",
      "7000 0.34665346 [array([[ 7.4902177, -7.4484634],\n",
      "       [15.7335005, 13.699939 ]], dtype=float32), array([[ 9.590768],\n",
      "       [-9.825583]], dtype=float32)]\n",
      "7100 0.3466493 [array([[ 7.5068145, -7.4666257],\n",
      "       [15.800897 , 13.764937 ]], dtype=float32), array([[ 9.641229],\n",
      "       [-9.879125]], dtype=float32)]\n",
      "7200 0.34664565 [array([[ 7.523302 , -7.4846473],\n",
      "       [15.867966 , 13.829703 ]], dtype=float32), array([[ 9.691594],\n",
      "       [-9.932521]], dtype=float32)]\n",
      "7300 0.3466418 [array([[ 7.5396905, -7.5025096],\n",
      "       [15.934841 , 13.894256 ]], dtype=float32), array([[ 9.741874],\n",
      "       [-9.985779]], dtype=float32)]\n",
      "7400 0.34663823 [array([[ 7.555977 , -7.5202403],\n",
      "       [16.001604 , 13.958582 ]], dtype=float32), array([[  9.792053],\n",
      "       [-10.038894]], dtype=float32)]\n",
      "7500 0.346635 [array([[ 7.5721693, -7.5378203],\n",
      "       [16.067957 , 14.022712 ]], dtype=float32), array([[  9.8421545],\n",
      "       [-10.0918865]], dtype=float32)]\n",
      "7600 0.34663194 [array([[ 7.5882654, -7.555268 ],\n",
      "       [16.134207 , 14.086648 ]], dtype=float32), array([[  9.892184],\n",
      "       [-10.144762]], dtype=float32)]\n",
      "7700 0.34662887 [array([[ 7.604276 , -7.5725837],\n",
      "       [16.200415 , 14.150395 ]], dtype=float32), array([[  9.942134],\n",
      "       [-10.197512]], dtype=float32)]\n",
      "7800 0.34662598 [array([[ 7.6201887, -7.5897727],\n",
      "       [16.266197 , 14.21396  ]], dtype=float32), array([[  9.9920225],\n",
      "       [-10.250156 ]], dtype=float32)]\n",
      "7900 0.3466234 [array([[ 7.6360173, -7.6068163],\n",
      "       [16.33177  , 14.277356 ]], dtype=float32), array([[ 10.041843],\n",
      "       [-10.302689]], dtype=float32)]\n",
      "8000 0.34662074 [array([[ 7.6517606, -7.623749 ],\n",
      "       [16.39722  , 14.34059  ]], dtype=float32), array([[ 10.091602],\n",
      "       [-10.355127]], dtype=float32)]\n",
      "8100 0.34661856 [array([[ 7.667423, -7.640594],\n",
      "       [16.46253 , 14.403643]], dtype=float32), array([[ 10.141303],\n",
      "       [-10.40746 ]], dtype=float32)]\n",
      "8200 0.3466161 [array([[ 7.6830025, -7.657289 ],\n",
      "       [16.52767  , 14.466551 ]], dtype=float32), array([[ 10.190949],\n",
      "       [-10.459705]], dtype=float32)]\n",
      "8300 0.34661406 [array([[ 7.698501, -7.673837],\n",
      "       [16.592749, 14.529321]], dtype=float32), array([[ 10.240548],\n",
      "       [-10.511865]], dtype=float32)]\n",
      "8400 0.34661192 [array([[ 7.713922, -7.690308],\n",
      "       [16.657787, 14.591939]], dtype=float32), array([[ 10.290094],\n",
      "       [-10.563939]], dtype=float32)]\n",
      "8500 0.34661004 [array([[ 7.729267, -7.706688],\n",
      "       [16.72247 , 14.654402]], dtype=float32), array([[ 10.339596],\n",
      "       [-10.615924]], dtype=float32)]\n",
      "8600 0.34660813 [array([[ 7.7445292, -7.72293  ],\n",
      "       [16.786581 , 14.716745 ]], dtype=float32), array([[ 10.389056],\n",
      "       [-10.667829]], dtype=float32)]\n",
      "8700 0.34660655 [array([[ 7.759717, -7.739113],\n",
      "       [16.850922, 14.778941]], dtype=float32), array([[ 10.438495],\n",
      "       [-10.719666]], dtype=float32)]\n",
      "8800 0.34660465 [array([[ 7.774847, -7.755177],\n",
      "       [16.915869, 14.841015]], dtype=float32), array([[ 10.487876],\n",
      "       [-10.77143 ]], dtype=float32)]\n",
      "8900 0.3466033 [array([[ 7.789914 , -7.771127 ],\n",
      "       [16.97919  , 14.9029665]], dtype=float32), array([[ 10.537231],\n",
      "       [-10.823128]], dtype=float32)]\n",
      "9000 0.3466016 [array([[ 7.804881 , -7.7868586],\n",
      "       [17.043243 , 14.964835 ]], dtype=float32), array([[ 10.586574],\n",
      "       [-10.874763]], dtype=float32)]\n",
      "9100 0.3466004 [array([[ 7.819828, -7.802689],\n",
      "       [17.107286, 15.02654 ]], dtype=float32), array([[ 10.63584 ],\n",
      "       [-10.926333]], dtype=float32)]\n",
      "9200 0.34659892 [array([[ 7.834662 , -7.8183703],\n",
      "       [17.1704   , 15.08813  ]], dtype=float32), array([[ 10.685135],\n",
      "       [-10.977848]], dtype=float32)]\n",
      "9300 0.34659767 [array([[ 7.849477, -7.833869],\n",
      "       [17.234667, 15.14964 ]], dtype=float32), array([[ 10.734339],\n",
      "       [-11.029289]], dtype=float32)]\n",
      "9400 0.34659642 [array([[ 7.864172, -7.849246],\n",
      "       [17.297195, 15.211055]], dtype=float32), array([[ 10.783597],\n",
      "       [-11.080698]], dtype=float32)]\n",
      "9500 0.34659553 [array([[ 7.8788743, -7.864835 ],\n",
      "       [17.360884 , 15.272281 ]], dtype=float32), array([[ 10.832762],\n",
      "       [-11.132045]], dtype=float32)]\n",
      "9600 0.34659427 [array([[ 7.89342  , -7.8801713],\n",
      "       [17.424034 , 15.333441 ]], dtype=float32), array([[ 10.88197 ],\n",
      "       [-11.183347]], dtype=float32)]\n",
      "9700 0.34659338 [array([[ 7.9080176, -7.895215 ],\n",
      "       [17.486156 , 15.394568 ]], dtype=float32), array([[ 10.931103],\n",
      "       [-11.234592]], dtype=float32)]\n",
      "9800 0.34659213 [array([[ 7.922467 , -7.9104505],\n",
      "       [17.551657 , 15.455496 ]], dtype=float32), array([[ 10.980205],\n",
      "       [-11.285783]], dtype=float32)]\n",
      "9900 0.3465913 [array([[ 7.9368796, -7.925682 ],\n",
      "       [17.611576 , 15.516328 ]], dtype=float32), array([[ 11.028092],\n",
      "       [-11.335553]], dtype=float32)]\n",
      "10000 0.34659034 [array([[ 7.9513426, -7.940284 ],\n",
      "       [17.674229 , 15.577302 ]], dtype=float32), array([[ 11.074916],\n",
      "       [-11.384202]], dtype=float32)]\n",
      "\n",
      "Hypothesis:  [[2.2800410e-05]\n",
      " [4.9996525e-01]\n",
      " [9.9997437e-01]\n",
      " [4.9997455e-01]] \n",
      "Correct:  [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  0.75\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# tf.set_random_seed(777)  # for reproducibility\n",
    "learning_rate = 0.01\n",
    "\n",
    "x_data = [[0, 0],\n",
    "          [0, 1],\n",
    "          [1, 0],\n",
    "          [1, 1]]\n",
    "y_data = [[0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [0]]\n",
    "x_data = np.array(x_data, dtype=np.float32)\n",
    "y_data = np.array(y_data, dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2], name='x-input')\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name='y-input')\n",
    "\n",
    "with tf.name_scope(\"layer1\"):\n",
    "    W1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
    "    b1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "    layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "    w1_hist = tf.summary.histogram(\"weights1\", W1)\n",
    "    b1_hist = tf.summary.histogram(\"biases1\", b1)\n",
    "    layer1_hist = tf.summary.histogram(\"layer1\", layer1)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"layer2\"):\n",
    "    W2 = tf.Variable(tf.random_normal([2, 1]), name='weight2')\n",
    "    b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "    hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "    w2_hist = tf.summary.histogram(\"weights2\", W2)\n",
    "    b2_hist = tf.summary.histogram(\"biases2\", b2)\n",
    "    hypothesis_hist = tf.summary.histogram(\"hypothesis\", hypothesis)\n",
    "\n",
    "# cost/loss function\n",
    "with tf.name_scope(\"cost\"):\n",
    "    cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *\n",
    "                           tf.log(1 - hypothesis))\n",
    "    cost_summ = tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "accuracy_summ = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # tensorboard --logdir=./logs/xor_logs\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(\"./logs/xor_log\")\n",
    "    writer.add_graph(sess.graph)  # Show the graph\n",
    "\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        summary, _ = sess.run([merged_summary, train], feed_dict={X: x_data, Y: y_data})\n",
    "        writer.add_summary(summary, global_step=step)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={\n",
    "                  X: x_data, Y: y_data}), sess.run([W1, W2]))\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tensorboard --logdir=='./logs/xor_log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
