{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 텐서플로우를 구성하는 가장 기초적인 데이터 단위\n",
    " - n 차원 배열의 집합 또는 n 차원 배열을 의미\n",
    " - rank: 텐서의 차원\n",
    " - 텐서의 표현은 `numpy` 배열을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3. # a rank 0 tensor; a scalar with shape []\n",
    "[1., 2., 3.] # a rank 1 tensor; a vector with shape [3],\n",
    "[[1., 2., 3.], [4., 5., 6.]] # a rank 2 tensor; a matrix with shape [2, 3],\n",
    "[[[1., 2., 3.]], [[7., 8., 9.]]] # a rank 3 tensor with shape [2, 1, 3]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TensorFlow programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 1) 연산 그래프(computational graph) 정의\n",
    "  - 연산그래프는 텐서플로우 작업을 순차적으로 정의(표현)한 것으로 노드와 에지를 갖는 그래프 형태를 갖음 \n",
    "  - 연산그래프의 노드에는 텐서를 입력값으로 받아 연산하는 작업들이 위치 : `tf.Operation`\n",
    "  - 연산그래프의 에지에는 노드에 정의된 연산간에 주고 받는 데이터 들을 표현(텐서들이 그래프 상에서 흐름.) `tf.Tensor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 2) 연산 그래프를 실행\n",
    "  - 연산그래프의 실행은 `tf.Session` 객체,텐서플로우가 실행되는 환경을 만들어서 진행됨\n",
    "  - 연산그래프의 작업을 CPU, GPU에 배정하고 실행을 위한 메서드를 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [default 그래프에 정의하기]\n",
    " - 3개의 노드(2개: constant op, 1개 matmul op)\n",
    " - 특정 그래프 객체에 명시적으로 연산을 정의하지 않는한 모든 연산은 전역 default 그래프에 정의됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "mat_a = tf.constant([[3.0, 3.0]], dtype=tf.float32)\n",
    "mat_b = tf.constant([[2.0],[2.0]], dtype=tf.float32)\n",
    "product = tf.matmul(mat_a, mat_b)\n",
    "\n",
    "print(tf.get_default_graph() is product.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [특정 그래프에 연산 정의하기]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "g_1 = tf.Graph()\n",
    "with g_1.as_default():\n",
    "    mat_a = tf.constant([[3.0, 3.0]], dtype=tf.float32)\n",
    "    mat_b = tf.constant([[2.0],[2.0]], dtype=tf.float32)\n",
    "    product = tf.matmul(mat_a, mat_b)\n",
    "    print(product.graph is g_1)\n",
    "\n",
    "g_2 = tf.Graph()\n",
    "with g_2.as_default():\n",
    "    mat_a = tf.constant([[3.0, 3.0]], dtype=tf.float32)\n",
    "    mat_b = tf.constant([[2.0],[2.0]], dtype=tf.float32)\n",
    "    product = tf.matmul(mat_a, mat_b)\n",
    "    print(product.graph is g_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [그래프 실행하기]\n",
    " - session 객체의 run 매서드 호출\n",
    " - default 그래프에 정의한 3개의 작업이 실행 (graph=None)\n",
    " - 사용한 session 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session(graph=g_2)\n",
    "print(sess.run(product))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - session 컨텍스트 매니저 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g_2) as sess:\n",
    "    print(sess.run(product))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TensorFlow tf.constant, tf.Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 연산 그래프에 정의된 연산을 수행하기 위해 필요한 데이터 값을 입력 위한 수단 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3-1. tf.constant\n",
    " - 상수 텐서를 생성하는 작업으로, `tf.constant` 연산 정의시 제공한 초기값을 갖는 텐서를 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3-2. tf.Variable\n",
    " - 텐서플로우 프로그램에서 연산의 결과가 공유되고, 상태를 유지해야하는 경우 사용 \n",
    "   - ex) 학습을 진행하면서 모델의 파라미터가 업데이트 되야하므로 모델의 파라미터를 변수로 표현\n",
    " - 변수 연산을 정의하기 위해 텐서를 초기값으로 부여, 초기값으로 제공한 텐서로 변수 type과 shape이 결정됨\n",
    " - 변수 연산이 정의되면 타입과 변수 type과 shape은 고정됨, 변수 값인 텐서를 assign 메서드로 변경\n",
    " - 연산을 실행하기 전, 그래프 상에 정의된 변수를 명시적으로 초기화하는 작업 필요\n",
    "   - 초기화 연산을 실행(`tf.global_variable_initializer()`), 변수 값이 저장된 파일에서 복구, `assign` 메서드 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "state = tf.Variable(0, name=\"counter\")\n",
    "one = tf.constant(1)\n",
    "new_value = tf.add(state, one)\n",
    "update = tf.assign(state, new_value)\n",
    "init_op = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(state))\n",
    "    for _ in range(3):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### [변수의 저장과 복구]\n",
    "  - 변수를 이름과 텐서 값을 매핑해놓은 바이너리 파일(`.ckpt`)에 저장 가능\n",
    "  - `tf.train.Saver()` 객체를 이용하여 그래프 전체 변수와 지정된 리스트 변수를 저장하고 복구\n",
    "  - 저장될 때 사용되는 변수 명은 `Variable.name`이 기본 값\n",
    "  - `tf.train.Saver()` 객체에 딕셔너리를 저장할 이름(key), 저장할 값(value)로 전달하여 저장시 사용할 이름을 변경하거나 변수를 선택적으로 저장 가능\n",
    "    - ex) `tf.train.Saver({\"saved_v\":v})`\n",
    "  - 전체 변수를 파일에서 복구 시 변수 초기화가 필요 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: ./tmp/ckpt/model.ckpt\n",
      "tensor_name:  counter\n",
      "0\n",
      "tensor_name:  v1\n",
      "[1. 1. 1.]\n",
      "tensor_name:  v2\n",
      "[-1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "# Create some variables.\n",
    "import tensorflow as tf\n",
    "import os, shutil\n",
    "\n",
    "v1 = tf.Variable(tf.zeros([3]), name=\"v1\")\n",
    "v2 = tf.Variable(tf.zeros([3]), name=\"v2\")\n",
    "    \n",
    "inc_v1 = v1.assign(v1+1)\n",
    "dec_v2 = v2.assign(v2-1)\n",
    "\n",
    "# Add an op to initialize the variables.\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, initialize the variables, do some work, and save the\n",
    "# variables to disk.\n",
    "with tf.Session() as sess:\n",
    "  sess.run(init_op)\n",
    "  # Do some work with the model.\n",
    "  sess.run([inc_v1, dec_v2])\n",
    "  # Save the variables to disk.\n",
    "  shutil.rmtree(\"./tmp/ckpt\")\n",
    "  os.mkdir(\"./tmp/ckpt\")\n",
    "  save_path = saver.save(sess, \"./tmp/ckpt/model.ckpt\")\n",
    "  print(\"Model saved in path: %s\" % save_path)\n",
    "    \n",
    "    \n",
    "from tensorflow.python.tools import inspect_checkpoint as chkp\n",
    "chkp.print_tensors_in_checkpoint_file(save_path, tensor_name='',  all_tensors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt/model.ckpt\n",
      "Model restored.\n",
      "v1 : [1. 1. 1.]\n",
      "v2 : [-1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Create some variables.\n",
    "v1 = tf.Variable(tf.zeros([3]), name=\"v1\")\n",
    "v2 = tf.Variable(tf.zeros([3]), name=\"v2\")\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "  # Restore variables from disk.\n",
    "  saver.restore(sess, \"./tmp/ckpt/model.ckpt\")\n",
    "  print(\"Model restored.\")\n",
    "  # Check the values of the variables\n",
    "  print(\"v1 : %s\" % v1.eval())\n",
    "  print(\"v2 : %s\" % v2.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### - tf.get_variable()\n",
    "  - `tf.Variable`과 같이 변수 정의하는 다른 방법으로 생성된 변수를 가져오거나 존재하지 않을 시 새롭게 생성\n",
    "  - `tf.variable_scope`가 `tf.get_variable`로 정의된 변수의 네임스페이스를 관리\n",
    "     - ex) 매우 깊은 층을 갖는 심층심경망 네트워크 구현시 각 층마다 변수를 정의하는 데 따른 불편함을 해결 \n",
    "     - 코드 모듈화를 더 쉽게할 수 있다는 이점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "weight1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
    "bias1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "weight2 = tf.Variable(tf.random_normal([2, 2]), name='weight2')\n",
    "bias2 = tf.Variable(tf.random_normal([2]), name='bias2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "with tf.variable_scope(\"layer1\", reuse=tf.AUTO_REUSE):\n",
    "    weight = tf.get_variable(\"weight\", shape=[2,2], initializer = tf.random_normal_initializer)\n",
    "    bias = tf.get_variable(\"bias\", shape=[2], initializer = tf.random_normal_initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fetches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 그래프 상에 정의된 작업 하나 이상의 작업 실행 결과 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([21.], dtype=float32), array([7.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "input1 = tf.constant([3.0])\n",
    "input2 = tf.constant([2.0])\n",
    "input3 = tf.constant([5.0])\n",
    "intermed = tf.add(input2, input3)\n",
    "mul = tf.multiply(input1, intermed)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  result = sess.run([mul, intermed])\n",
    "  print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 실행 시점에 정의된 연산 그래프 상으로 텐서 값을 제공하는 매커니즘\n",
    " - tf.placeholder를 이용 텐서(데이터)가 연산 그래프에 입력될 입력 공간을 확보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9987452  0.643013   0.85683334 0.6816925 ]\n",
      " [1.2721993  1.6664381  1.1944566  1.3873851 ]\n",
      " [0.18811429 0.16229677 0.15458071 0.14437959]\n",
      " [1.1358577  1.2654186  1.4638474  1.2737625 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x1 = tf.placeholder(tf.float32, shape=(4, 4), name='input1')\n",
    "x2 = tf.placeholder(tf.float32, shape=(4, 4), name='input2')\n",
    "y = tf.matmul(x1, x2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  arr = np.random.rand(4, 4)\n",
    "  print(sess.run(y, feed_dict={x1: arr, x2:arr}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization : Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 텐서플로우가 제공하는 텐서보드를 활용하여 연산 그래프를 시각화\n",
    " - 그래프 실행 후 연산 결과 시각화\n",
    " - `tf.summary.FileWriter()` 객체에 연산 그래프와 연산 결과 값을 저장 후 텐서보드로 시각화   \n",
    " - 벡터: `tf.summary.histogram()`, 스칼라: `tf.summary.scalar()`로 시각화할 연산 값 설정\n",
    " - 텐서보드 실행 => 터미널에서 `tensorboard --logdir=\"./logs/xor_log\"` 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.75501335 [array([[ 0.9242899 , -0.23761767],\n",
      "       [ 0.4561836 ,  0.30244088]], dtype=float32), array([[ 0.68182355],\n",
      "       [-1.194301  ]], dtype=float32)]\n",
      "100 0.6936321 [array([[ 0.5797159 , -0.02262164],\n",
      "       [-0.0215434 ,  0.34096748]], dtype=float32), array([[ 0.40056005],\n",
      "       [-1.4360051 ]], dtype=float32)]\n",
      "200 0.69090986 [array([[ 0.76052016,  0.04726546],\n",
      "       [-0.6270058 ,  0.05975845]], dtype=float32), array([[ 0.45329523],\n",
      "       [-1.4393609 ]], dtype=float32)]\n",
      "300 0.64168453 [array([[ 2.2156148 ,  0.49971673],\n",
      "       [-2.2514682 , -0.3826279 ]], dtype=float32), array([[ 1.2942744],\n",
      "       [-1.5597004]], dtype=float32)]\n",
      "400 0.39380413 [array([[ 4.1982727,  2.5184634],\n",
      "       [-4.1615505, -2.282931 ]], dtype=float32), array([[ 3.1407025],\n",
      "       [-2.5111883]], dtype=float32)]\n",
      "500 0.19086213 [array([[ 5.285746 ,  4.044589 ],\n",
      "       [-5.2259865, -3.8879325]], dtype=float32), array([[ 4.496205 ],\n",
      "       [-4.1228604]], dtype=float32)]\n",
      "600 0.1121998 [array([[ 5.8924704,  4.845564 ],\n",
      "       [-5.83518  , -4.709812 ]], dtype=float32), array([[ 5.40982 ],\n",
      "       [-5.203287]], dtype=float32)]\n",
      "700 0.07601307 [array([[ 6.2966037,  5.3458915],\n",
      "       [-6.24395  , -5.2196574]], dtype=float32), array([[ 6.089712],\n",
      "       [-5.966652]], dtype=float32)]\n",
      "800 0.0559155 [array([[ 6.596837 ,  5.7026973],\n",
      "       [-6.5483665, -5.582244 ]], dtype=float32), array([[ 6.6350555],\n",
      "       [-6.559209 ]], dtype=float32)]\n",
      "900 0.043333367 [array([[ 6.834943 ,  5.97808  ],\n",
      "       [-6.7899857, -5.8616557]], dtype=float32), array([[ 7.0937657],\n",
      "       [-7.047361 ]], dtype=float32)]\n",
      "1000 0.03480646 [array([[ 7.0320077,  6.2016544],\n",
      "       [-6.9899874, -6.088263 ]], dtype=float32), array([[ 7.4920382],\n",
      "       [-7.465307 ]], dtype=float32)]\n",
      "1100 0.028695978 [array([[ 7.200057 ,  6.389608 ],\n",
      "       [-7.1605196, -6.278605 ]], dtype=float32), array([[ 7.8457046],\n",
      "       [-7.832782 ]], dtype=float32)]\n",
      "1200 0.024132162 [array([[ 7.3465667,  6.5516706],\n",
      "       [-7.309156 , -6.4426184]], dtype=float32), array([[ 8.165057],\n",
      "       [-8.162195]], dtype=float32)]\n",
      "1300 0.020613264 [array([[ 7.4764876,  6.6941276],\n",
      "       [-7.4409237, -6.586706 ]], dtype=float32), array([[ 8.457182],\n",
      "       [-8.461859]], dtype=float32)]\n",
      "1400 0.0178305 [array([[ 7.5932646,  6.8212595],\n",
      "       [-7.559322 , -6.7152233]], dtype=float32), array([[ 8.727163],\n",
      "       [-8.737624]], dtype=float32)]\n",
      "1500 0.015584243 [array([[ 7.6993876,  6.9361067],\n",
      "       [-7.6668825, -6.8312674]], dtype=float32), array([[ 8.978789],\n",
      "       [-8.99376 ]], dtype=float32)]\n",
      "1600 0.013739807 [array([[ 7.79671  ,  7.0409007],\n",
      "       [-7.7654905, -6.9371085]], dtype=float32), array([[ 9.214954],\n",
      "       [-9.233497]], dtype=float32)]\n",
      "1700 0.012203436 [array([[ 7.886652 ,  7.1373305],\n",
      "       [-7.85659  , -7.0344596]], dtype=float32), array([[ 9.437918],\n",
      "       [-9.459326]], dtype=float32)]\n",
      "1800 0.0109078605 [array([[ 7.9703183,  7.226699 ],\n",
      "       [-7.941308 , -7.1246467]], dtype=float32), array([[ 9.649489],\n",
      "       [-9.673219]], dtype=float32)]\n",
      "1900 0.009803701 [array([[ 8.048591,  7.310034],\n",
      "       [-8.020545, -7.208713]], dtype=float32), array([[ 9.851127],\n",
      "       [-9.87675 ]], dtype=float32)]\n",
      "2000 0.008853924 [array([[ 8.122186 ,  7.388154 ],\n",
      "       [-8.095022 , -7.2874975]], dtype=float32), array([[ 10.044051],\n",
      "       [-10.07123 ]], dtype=float32)]\n",
      "2100 0.008030277 [array([[ 8.191685 ,  7.461736 ],\n",
      "       [-8.165333 , -7.3616776]], dtype=float32), array([[ 10.229263],\n",
      "       [-10.257726]], dtype=float32)]\n",
      "2200 0.0073108133 [array([[ 8.257569 ,  7.53133  ],\n",
      "       [-8.231971 , -7.4318166]], dtype=float32), array([[ 10.407605],\n",
      "       [-10.437133]], dtype=float32)]\n",
      "2300 0.006678339 [array([[ 8.320247 ,  7.5973964],\n",
      "       [-8.295344 , -7.498379 ]], dtype=float32), array([[ 10.5798  ],\n",
      "       [-10.610214]], dtype=float32)]\n",
      "2400 0.0061190748 [array([[ 8.3800535,  7.660319 ],\n",
      "       [-8.355809 , -7.56176  ]], dtype=float32), array([[ 10.746466],\n",
      "       [-10.777617]], dtype=float32)]\n",
      "2500 0.0056220163 [array([[ 8.43729 ,  7.72043 ],\n",
      "       [-8.413659, -7.622291]], dtype=float32), array([[ 10.9081335],\n",
      "       [-10.939905 ]], dtype=float32)]\n",
      "2600 0.005178157 [array([[ 8.492206 ,  7.778012 ],\n",
      "       [-8.4691515, -7.6802607]], dtype=float32), array([[ 11.065279],\n",
      "       [-11.097556]], dtype=float32)]\n",
      "2700 0.0047800443 [array([[ 8.545016 ,  7.833302 ],\n",
      "       [-8.522507 , -7.7359104]], dtype=float32), array([[ 11.2183],\n",
      "       [-11.251 ]], dtype=float32)]\n",
      "2800 0.0044216653 [array([[ 8.595912 ,  7.8865128],\n",
      "       [-8.573916 , -7.7894554]], dtype=float32), array([[ 11.36756 ],\n",
      "       [-11.400608]], dtype=float32)]\n",
      "2900 0.0040977704 [array([[ 8.645057,  7.937829],\n",
      "       [-8.62355 , -7.841083]], dtype=float32), array([[ 11.513372],\n",
      "       [-11.546711]], dtype=float32)]\n",
      "3000 0.0038041966 [array([[ 8.692599,  7.987413],\n",
      "       [-8.671558, -7.890956]], dtype=float32), array([[ 11.656026],\n",
      "       [-11.689596]], dtype=float32)]\n",
      "3100 0.0035371939 [array([[ 8.738668,  8.035406],\n",
      "       [-8.718069, -7.939218]], dtype=float32), array([[ 11.795769],\n",
      "       [-11.829529]], dtype=float32)]\n",
      "3200 0.0032937657 [array([[ 8.783379,  8.081934],\n",
      "       [-8.763199, -7.985998]], dtype=float32), array([[ 11.93283 ],\n",
      "       [-11.966739]], dtype=float32)]\n",
      "3300 0.0030712334 [array([[ 8.826834 ,  8.127108 ],\n",
      "       [-8.8070545, -8.031409 ]], dtype=float32), array([[ 12.067416],\n",
      "       [-12.101436]], dtype=float32)]\n",
      "3400 0.0028672821 [array([[ 8.86912 ,  8.171027],\n",
      "       [-8.849727, -8.075554]], dtype=float32), array([[ 12.199706],\n",
      "       [-12.233813]], dtype=float32)]\n",
      "3500 0.0026799128 [array([[ 8.910326,  8.213787],\n",
      "       [-8.891301, -8.118523]], dtype=float32), array([[ 12.329869 ],\n",
      "       [-12.3640375]], dtype=float32)]\n",
      "3600 0.0025075625 [array([[ 8.9505205,  8.255462 ],\n",
      "       [-8.93185  , -8.160397 ]], dtype=float32), array([[ 12.458056],\n",
      "       [-12.492264]], dtype=float32)]\n",
      "3700 0.0023486104 [array([[ 8.989774,  8.29613 ],\n",
      "       [-8.971446, -8.20125 ]], dtype=float32), array([[ 12.584409],\n",
      "       [-12.618634]], dtype=float32)]\n",
      "3800 0.0022017804 [array([[ 9.028147,  8.335855],\n",
      "       [-9.010146, -8.241153]], dtype=float32), array([[ 12.70905],\n",
      "       [-12.74328]], dtype=float32)]\n",
      "3900 0.0020659175 [array([[ 9.065699,  8.374696],\n",
      "       [-9.048011, -8.280163]], dtype=float32), array([[ 12.832098],\n",
      "       [-12.866316]], dtype=float32)]\n",
      "4000 0.0019399719 [array([[ 9.102473,  8.412712],\n",
      "       [-9.085091, -8.318336]], dtype=float32), array([[ 12.953658],\n",
      "       [-12.987852]], dtype=float32)]\n",
      "4100 0.001823119 [array([[ 9.13852 ,  8.44995 ],\n",
      "       [-9.121433, -8.355722]], dtype=float32), array([[ 13.073831],\n",
      "       [-13.107986]], dtype=float32)]\n",
      "4200 0.0017145044 [array([[ 9.173881,  8.486456],\n",
      "       [-9.157076, -8.39237 ]], dtype=float32), array([[ 13.1927  ],\n",
      "       [-13.226814]], dtype=float32)]\n",
      "4300 0.0016133944 [array([[ 9.208593,  8.522271],\n",
      "       [-9.192064, -8.428319]], dtype=float32), array([[ 13.310353],\n",
      "       [-13.344415]], dtype=float32)]\n",
      "4400 0.0015192194 [array([[ 9.242697,  8.557436],\n",
      "       [-9.226432, -8.463609]], dtype=float32), array([[ 13.426868],\n",
      "       [-13.460869]], dtype=float32)]\n",
      "4500 0.0014313655 [array([[ 9.276219,  8.591982],\n",
      "       [-9.260214, -8.498277]], dtype=float32), array([[ 13.5423155],\n",
      "       [-13.57625  ]], dtype=float32)]\n",
      "4600 0.0013493389 [array([[ 9.309195,  8.625948],\n",
      "       [-9.29344 , -8.532354]], dtype=float32), array([[ 13.656759],\n",
      "       [-13.690619]], dtype=float32)]\n",
      "4700 0.0012726455 [array([[ 9.341649,  8.659361],\n",
      "       [-9.326136, -8.565874]], dtype=float32), array([[ 13.770263],\n",
      "       [-13.804047]], dtype=float32)]\n",
      "4800 0.0012008816 [array([[ 9.37361  ,  8.6922455],\n",
      "       [-9.358331 , -8.598863 ]], dtype=float32), array([[ 13.882881],\n",
      "       [-13.916586]], dtype=float32)]\n",
      "4900 0.0011337324 [array([[ 9.405099,  8.72463 ],\n",
      "       [-9.39005 , -8.631345]], dtype=float32), array([[ 13.994668],\n",
      "       [-14.02829 ]], dtype=float32)]\n",
      "5000 0.0010707497 [array([[ 9.436142,  8.756539],\n",
      "       [-9.421317, -8.663347]], dtype=float32), array([[ 14.105674],\n",
      "       [-14.139208]], dtype=float32)]\n",
      "5100 0.0010116791 [array([[ 9.466757 ,  8.787997 ],\n",
      "       [-9.4521475, -8.694893 ]], dtype=float32), array([[ 14.215946],\n",
      "       [-14.249392]], dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5200 0.0009562364 [array([[ 9.496965,  8.819018],\n",
      "       [-9.482567, -8.725998]], dtype=float32), array([[ 14.325525],\n",
      "       [-14.35888 ]], dtype=float32)]\n",
      "5300 0.00090413785 [array([[ 9.526784,  8.849628],\n",
      "       [-9.512591, -8.75669 ]], dtype=float32), array([[ 14.434451],\n",
      "       [-14.467713]], dtype=float32)]\n",
      "5400 0.0008552037 [array([[ 9.556229,  8.879844],\n",
      "       [-9.542236, -8.786982]], dtype=float32), array([[ 14.542766],\n",
      "       [-14.575934]], dtype=float32)]\n",
      "5500 0.0008091503 [array([[ 9.585318,  8.909679],\n",
      "       [-9.571521, -8.816889]], dtype=float32), array([[ 14.650499],\n",
      "       [-14.683572]], dtype=float32)]\n",
      "5600 0.00076578325 [array([[ 9.614065,  8.939154],\n",
      "       [-9.600459, -8.846429]], dtype=float32), array([[ 14.757689],\n",
      "       [-14.790665]], dtype=float32)]\n",
      "5700 0.00072498305 [array([[ 9.642482,  8.96828 ],\n",
      "       [-9.629064, -8.87562 ]], dtype=float32), array([[ 14.864364],\n",
      "       [-14.897243]], dtype=float32)]\n",
      "5800 0.00068652554 [array([[ 9.670582,  8.997069],\n",
      "       [-9.657347, -8.904471]], dtype=float32), array([[ 14.970554],\n",
      "       [-15.003334]], dtype=float32)]\n",
      "5900 0.00065026147 [array([[ 9.6983795,  9.025539 ],\n",
      "       [-9.685324 , -8.9330015]], dtype=float32), array([[ 15.076287],\n",
      "       [-15.10897 ]], dtype=float32)]\n",
      "6000 0.0006160862 [array([[ 9.725885,  9.053701],\n",
      "       [-9.713005, -8.961216]], dtype=float32), array([[ 15.181585],\n",
      "       [-15.21417 ]], dtype=float32)]\n",
      "6100 0.00058382057 [array([[ 9.753111,  9.081565],\n",
      "       [-9.7404  , -8.989133]], dtype=float32), array([[ 15.286478],\n",
      "       [-15.318964]], dtype=float32)]\n",
      "6200 0.00055337494 [array([[ 9.780066,  9.10914 ],\n",
      "       [-9.767521, -9.016758]], dtype=float32), array([[ 15.390984],\n",
      "       [-15.423372]], dtype=float32)]\n",
      "6300 0.00052460004 [array([[ 9.80676 ,  9.136437],\n",
      "       [-9.794378, -9.044105]], dtype=float32), array([[ 15.495125],\n",
      "       [-15.52742 ]], dtype=float32)]\n",
      "6400 0.00049743615 [array([[ 9.833197,  9.163469],\n",
      "       [-9.82098 , -9.071183]], dtype=float32), array([[ 15.598926],\n",
      "       [-15.631121]], dtype=float32)]\n",
      "6500 0.00047176378 [array([[ 9.859396,  9.190246],\n",
      "       [-9.847329, -9.097995]], dtype=float32), array([[ 15.702398],\n",
      "       [-15.734501]], dtype=float32)]\n",
      "6600 0.00044750836 [array([[ 9.885351 ,  9.216766 ],\n",
      "       [-9.8734455, -9.12456  ]], dtype=float32), array([[ 15.805565],\n",
      "       [-15.83757 ]], dtype=float32)]\n",
      "6700 0.00042453557 [array([[ 9.911083,  9.243051],\n",
      "       [-9.899324, -9.150881]], dtype=float32), array([[ 15.908437],\n",
      "       [-15.940357]], dtype=float32)]\n",
      "6800 0.00040283042 [array([[ 9.936596,  9.269096],\n",
      "       [-9.924981, -9.176968]], dtype=float32), array([[ 16.011034],\n",
      "       [-16.042866]], dtype=float32)]\n",
      "6900 0.00038225867 [array([[ 9.961887,  9.294921],\n",
      "       [-9.950423, -9.202821]], dtype=float32), array([[ 16.113375],\n",
      "       [-16.145128]], dtype=float32)]\n",
      "7000 0.00036282025 [array([[ 9.986972,  9.32052 ],\n",
      "       [-9.975654, -9.228455]], dtype=float32), array([[ 16.215477],\n",
      "       [-16.247126]], dtype=float32)]\n",
      "7100 0.00034444057 [array([[ 10.011857,   9.345906],\n",
      "       [-10.000674,  -9.253872]], dtype=float32), array([[ 16.317352],\n",
      "       [-16.348885]], dtype=float32)]\n",
      "7200 0.00032698538 [array([[ 10.036545,   9.371086],\n",
      "       [-10.025497,  -9.279079]], dtype=float32), array([[ 16.418997],\n",
      "       [-16.450438]], dtype=float32)]\n",
      "7300 0.0003104249 [array([[ 10.061036,   9.396065],\n",
      "       [-10.050129,  -9.304083]], dtype=float32), array([[ 16.520435],\n",
      "       [-16.551788]], dtype=float32)]\n",
      "7400 0.0002947888 [array([[ 10.085343,   9.420846],\n",
      "       [-10.074572,  -9.328888]], dtype=float32), array([[ 16.62168],\n",
      "       [-16.65295]], dtype=float32)]\n",
      "7500 0.00027997277 [array([[ 10.109469 ,   9.4454365],\n",
      "       [-10.098832 ,  -9.353501 ]], dtype=float32), array([[ 16.722736],\n",
      "       [-16.753925]], dtype=float32)]\n",
      "7600 0.0002659469 [array([[ 10.133428,   9.469841],\n",
      "       [-10.122911,  -9.377931]], dtype=float32), array([[ 16.823635],\n",
      "       [-16.854706]], dtype=float32)]\n",
      "7700 0.00025259197 [array([[ 10.157213,   9.494065],\n",
      "       [-10.146814,  -9.402181]], dtype=float32), array([[ 16.924358],\n",
      "       [-16.955345]], dtype=float32)]\n",
      "7800 0.00023993771 [array([[ 10.18082 ,   9.518115],\n",
      "       [-10.17055 ,  -9.42625 ]], dtype=float32), array([[ 17.024916],\n",
      "       [-17.055841]], dtype=float32)]\n",
      "7900 0.00022795437 [array([[ 10.204266,   9.541995],\n",
      "       [-10.194124,  -9.450142]], dtype=float32), array([[ 17.125332],\n",
      "       [-17.156168]], dtype=float32)]\n",
      "8000 0.00021659714 [array([[ 10.227558,   9.565699],\n",
      "       [-10.217535,  -9.473861]], dtype=float32), array([[ 17.225616],\n",
      "       [-17.25636 ]], dtype=float32)]\n",
      "8100 0.0002058064 [array([[ 10.250685,   9.589239],\n",
      "       [-10.240782,  -9.497413]], dtype=float32), array([[ 17.325752],\n",
      "       [-17.356432]], dtype=float32)]\n",
      "8200 0.00019556723 [array([[ 10.273664,   9.612625],\n",
      "       [-10.263883,  -9.520814]], dtype=float32), array([[ 17.425756],\n",
      "       [-17.456377]], dtype=float32)]\n",
      "8300 0.00018584979 [array([[ 10.2965   ,   9.635849 ],\n",
      "       [-10.286824 ,  -9.5440445]], dtype=float32), array([[ 17.525694],\n",
      "       [-17.556187]], dtype=float32)]\n",
      "8400 0.00017663921 [array([[ 10.31918 ,   9.658918],\n",
      "       [-10.309623,  -9.567126]], dtype=float32), array([[ 17.625448],\n",
      "       [-17.655941]], dtype=float32)]\n",
      "8500 0.00016786088 [array([[ 10.341727,   9.681845],\n",
      "       [-10.332274,  -9.590059]], dtype=float32), array([[ 17.725151],\n",
      "       [-17.75552 ]], dtype=float32)]\n",
      "8600 0.00015957447 [array([[ 10.364127,   9.704612],\n",
      "       [-10.354786,  -9.612837]], dtype=float32), array([[ 17.824715],\n",
      "       [-17.855082]], dtype=float32)]\n",
      "8700 0.00015170543 [array([[ 10.386401,   9.727247],\n",
      "       [-10.377155,  -9.635485]], dtype=float32), array([[ 17.924278],\n",
      "       [-17.954454]], dtype=float32)]\n",
      "8800 0.00014419413 [array([[ 10.408541,   9.749732],\n",
      "       [-10.399402,  -9.657985]], dtype=float32), array([[ 18.023659],\n",
      "       [-18.053827]], dtype=float32)]\n",
      "8900 0.00013710017 [array([[ 10.430534 ,   9.772088 ],\n",
      "       [-10.4215   ,  -9.6803465]], dtype=float32), array([[ 18.123032],\n",
      "       [-18.153051]], dtype=float32)]\n",
      "9000 0.00013033413 [array([[ 10.452407,   9.794305],\n",
      "       [-10.443478,  -9.702566]], dtype=float32), array([[ 18.22225 ],\n",
      "       [-18.252234]], dtype=float32)]\n",
      "9100 0.0001239407 [array([[ 10.474153,   9.816387],\n",
      "       [-10.465327,  -9.724651]], dtype=float32), array([[ 18.321432],\n",
      "       [-18.351387]], dtype=float32)]\n",
      "9200 0.00011781558 [array([[ 10.495764,   9.838347],\n",
      "       [-10.487042,  -9.746614]], dtype=float32), array([[ 18.420574],\n",
      "       [-18.450378]], dtype=float32)]\n",
      "9300 0.00011201836 [array([[ 10.517263,   9.860166],\n",
      "       [-10.50864 ,  -9.768431]], dtype=float32), array([[ 18.519566],\n",
      "       [-18.54937 ]], dtype=float32)]\n",
      "9400 0.00010651923 [array([[ 10.538649,   9.881863],\n",
      "       [-10.530121,  -9.790131]], dtype=float32), array([[ 18.618557],\n",
      "       [-18.64831 ]], dtype=float32)]\n",
      "9500 0.000101318175 [array([[ 10.559897,   9.903442],\n",
      "       [-10.551473,  -9.811714]], dtype=float32), array([[ 18.717525],\n",
      "       [-18.747143]], dtype=float32)]\n",
      "9600 9.6355594e-05 [array([[ 10.581037,   9.924892],\n",
      "       [-10.572707,  -9.833164]], dtype=float32), array([[ 18.816326],\n",
      "       [-18.845943]], dtype=float32)]\n",
      "9700 9.161657e-05 [array([[ 10.602066,   9.94622 ],\n",
      "       [-10.593829,  -9.854492]], dtype=float32), array([[ 18.915127],\n",
      "       [-18.944744]], dtype=float32)]\n",
      "9800 8.713092e-05 [array([[ 10.622991,   9.967435],\n",
      "       [-10.614839,  -9.875706]], dtype=float32), array([[ 19.013927],\n",
      "       [-19.043453]], dtype=float32)]\n",
      "9900 8.285392e-05 [array([[ 10.643798,   9.988538],\n",
      "       [-10.635739,  -9.896804]], dtype=float32), array([[ 19.11269 ],\n",
      "       [-19.142076]], dtype=float32)]\n",
      "10000 7.881538e-05 [array([[ 10.664489,  10.009526],\n",
      "       [-10.656523,  -9.917785]], dtype=float32), array([[ 19.2113  ],\n",
      "       [-19.240686]], dtype=float32)]\n",
      "\n",
      "Hypothesis:  [[7.1818540e-05]\n",
      " [9.9991333e-01]\n",
      " [9.9991441e-01]\n",
      " [7.1144939e-05]] \n",
      "Correct:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "x_data = [[0, 0],\n",
    "          [0, 1],\n",
    "          [1, 0],\n",
    "          [1, 1]]\n",
    "y_data = [[0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [0]]\n",
    "x_data = np.array(x_data, dtype=np.float32)\n",
    "y_data = np.array(y_data, dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2], name='x-input')\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name='y-input')\n",
    "\n",
    "with tf.name_scope(\"layer1\"):\n",
    "    W1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
    "    b1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "    layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "    w1_hist = tf.summary.histogram(\"weights1\", W1)\n",
    "    b1_hist = tf.summary.histogram(\"biases1\", b1)\n",
    "    layer1_hist = tf.summary.histogram(\"layer1\", layer1)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"layer2\"):\n",
    "    W2 = tf.Variable(tf.random_normal([2, 1]), name='weight2')\n",
    "    b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "    hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "    w2_hist = tf.summary.histogram(\"weights2\", W2)\n",
    "    b2_hist = tf.summary.histogram(\"biases2\", b2)\n",
    "    hypothesis_hist = tf.summary.histogram(\"hypothesis\", hypothesis)\n",
    "\n",
    "# cost/loss function\n",
    "with tf.name_scope(\"cost\"):\n",
    "    cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *\n",
    "                           tf.log(1 - hypothesis))\n",
    "    cost_summ = tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "accuracy_summ = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # tensorboard --logdir=./logs/xor_logs\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(\"./logs/xor_log\")\n",
    "    writer.add_graph(sess.graph)  # Show the graph\n",
    "\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        summary, _ = sess.run([merged_summary, train], feed_dict={X: x_data, Y: y_data})\n",
    "        writer.add_summary(summary, global_step=step)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={\n",
    "                  X: x_data, Y: y_data}), sess.run([W1, W2]))\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tensorboard --logdir='./logs/xor_log'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
