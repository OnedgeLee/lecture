{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 텐서플로우를 구성하는 가장 기초적인 데이터 단위\n",
    " - n 차원 배열의 집합 또는 n 차원 배열을 의미\n",
    " - rank: 텐서의 차원\n",
    " - 텐서의 표현은 `numpy` 배열을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3. # a rank 0 tensor; a scalar with shape []\n",
    "[1., 2., 3.] # a rank 1 tensor; a vector with shape [3],\n",
    "[[1., 2., 3.], [4., 5., 6.]] # a rank 2 tensor; a matrix with shape [2, 3],\n",
    "[[[1., 2., 3.]], [[7., 8., 9.]]] # a rank 3 tensor with shape [2, 1, 3]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TensorFlow programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 1) 연산 그래프(computational graph) 정의\n",
    "  - 연산그래프는 텐서플로우 작업을 순차적으로 정의(표현)한 것으로 노드와 에지를 갖는 그래프 형태를 갖음 \n",
    "  - 연산그래프의 노드에는 텐서를 입력값으로 받아 연산하는 작업들이 위치 : `tf.Operation`\n",
    "  - 연산그래프의 에지에는 노드에 정의된 연산간에 주고 받는 데이터 들을 표현(텐서들이 그래프 상에서 흐름.) `tf.Tensor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 2) 연산 그래프를 실행\n",
    "  - 연산그래프의 실행은 `tf.Session` 객체,텐서플로우가 실행되는 환경을 만들어서 진행됨\n",
    "  - 연산그래프의 작업을 CPU, GPU에 배정하고 실행을 위한 메서드를 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [default 그래프에 정의하기]\n",
    " - 3개의 노드(2개: constant op, 1개 matmul op)\n",
    " - 특정 그래프 객체에 명시적으로 연산을 정의하지 않는한 모든 연산은 전역 default 그래프에 정의됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "mat_a = tf.constant([[3.0, 3.0]], dtype=tf.float32)\n",
    "mat_b = tf.constant([[2.0],[2.0]], dtype=tf.float32)\n",
    "product = tf.matmul(mat_a, mat_b)\n",
    "\n",
    "print(tf.get_default_graph() is product.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [특정 그래프에 연산 정의하기]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "g_1 = tf.Graph()\n",
    "with g_1.as_default():\n",
    "    mat_a = tf.constant([[3.0, 3.0]], dtype=tf.float32)\n",
    "    mat_b = tf.constant([[2.0],[2.0]], dtype=tf.float32)\n",
    "    product = tf.matmul(mat_a, mat_b)\n",
    "    print(product.graph is g_1)\n",
    "\n",
    "g_2 = tf.Graph()\n",
    "with g_2.as_default():\n",
    "    mat_a = tf.constant([[3.0, 3.0]], dtype=tf.float32)\n",
    "    mat_b = tf.constant([[2.0],[2.0]], dtype=tf.float32)\n",
    "    product = tf.matmul(mat_a, mat_b)\n",
    "    print(product.graph is g_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [그래프 실행하기]\n",
    " - session 객체의 run 매서드 호출\n",
    " - default 그래프에 정의한 3개의 작업이 실행 (graph=None)\n",
    " - 사용한 session 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session(graph=g_2)\n",
    "print(sess.run(product))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - session 컨텍스트 매니저 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g_2) as sess:\n",
    "    print(sess.run(product))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TensorFlow tf.constant, tf.Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 연산 그래프에 정의된 연산을 수행하기 위해 필요한 데이터 값을 입력 위한 수단 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3-1. tf.constant\n",
    " - 상수 텐서를 생성하는 작업으로, `tf.constant` 연산 정의시 제공한 초기값을 갖는 텐서를 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3-2. tf.Variable\n",
    " - 텐서플로우 프로그램에서 연산의 결과가 공유되고, 상태를 유지해야하는 경우 사용 \n",
    "   - ex) 학습을 진행하면서 모델의 파라미터가 업데이트 되야하므로 모델의 파라미터를 변수로 표현\n",
    " - 변수 연산을 정의하기 위해 텐서를 초기값으로 부여, 초기값으로 제공한 텐서로 변수 type과 shape이 결정됨\n",
    " - 변수 연산이 정의되면 타입과 변수 type과 shape은 고정됨, 변수 값인 텐서를 assign 메서드로 변경\n",
    " - 연산을 실행하기 전, 그래프 상에 정의된 변수를 명시적으로 초기화하는 작업 필요\n",
    "   - 초기화 연산을 실행(`tf.global_variable_initializer()`), 변수 값이 저장된 파일에서 복구, `assign` 메서드 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "state = tf.Variable(0, name=\"counter\")\n",
    "one = tf.constant(1)\n",
    "new_value = tf.add(state, one)\n",
    "update = tf.assign(state, new_value)\n",
    "init_op = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(state))\n",
    "    for _ in range(3):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### [변수의 저장과 복구]\n",
    "  - 변수를 이름과 텐서 값을 매핑해놓은 바이너리 파일(`.ckpt`)에 저장 가능\n",
    "  - `tf.train.Saver()` 객체를 이용하여 그래프 전체 변수와 지정된 리스트 변수를 저장하고 복구\n",
    "  - 저장될 때 사용되는 변수 명은 `Variable.name`이 기본 값\n",
    "  - `tf.train.Saver()` 객체에 딕셔너리를 저장할 이름(key), 저장할 값(value)로 전달하여 저장시 사용할 이름을 변경하거나 변수를 선택적으로 저장 가능\n",
    "    - ex) `tf.train.Saver({\"saved_v\":v})`\n",
    "  - 전체 변수를 파일에서 복구 시 변수 초기화가 필요 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: ./tmp/ckpt/model.ckpt\n",
      "tensor_name:  counter\n",
      "0\n",
      "tensor_name:  v1\n",
      "[1. 1. 1.]\n",
      "tensor_name:  v2\n",
      "[-1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "# Create some variables.\n",
    "import tensorflow as tf\n",
    "import os, shutil\n",
    "\n",
    "v1 = tf.Variable(tf.zeros([3]), name=\"v1\")\n",
    "v2 = tf.Variable(tf.zeros([3]), name=\"v2\")\n",
    "    \n",
    "inc_v1 = v1.assign(v1+1)\n",
    "dec_v2 = v2.assign(v2-1)\n",
    "\n",
    "# Add an op to initialize the variables.\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, initialize the variables, do some work, and save the\n",
    "# variables to disk.\n",
    "with tf.Session() as sess:\n",
    "  sess.run(init_op)\n",
    "  sess.run([inc_v1, dec_v2])\n",
    "  # Save the variables to disk.\n",
    "  shutil.rmtree(\"./tmp/ckpt\")\n",
    "  os.mkdir(\"./tmp/ckpt\")\n",
    "  save_path = saver.save(sess, \"./tmp/ckpt/model.ckpt\")\n",
    "  print(\"Model saved in path: %s\" % save_path)\n",
    "    \n",
    "    \n",
    "from tensorflow.python.tools import inspect_checkpoint as chkp\n",
    "chkp.print_tensors_in_checkpoint_file(save_path, tensor_name='',  all_tensors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt/model.ckpt\n",
      "Model restored.\n",
      "v1 : [1. 1. 1.]\n",
      "v2 : [-1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Create some variables.\n",
    "v1 = tf.Variable(tf.zeros([3]), name=\"v1\")\n",
    "v2 = tf.Variable(tf.zeros([3]), name=\"v2\")\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "  # Restore variables from disk.\n",
    "  saver.restore(sess, \"./tmp/ckpt/model.ckpt\")\n",
    "  print(\"Model restored.\")\n",
    "  # Check the values of the variables\n",
    "  print(\"v1 : %s\" % v1.eval())\n",
    "  print(\"v2 : %s\" % v2.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### - tf.get_variable()\n",
    "  - `tf.Variable`과 같이 변수 정의하는 다른 방법으로 생성된 변수를 가져오거나 존재하지 않을 시 새롭게 생성\n",
    "  - `tf.variable_scope`가 `tf.get_variable`로 정의된 변수의 네임스페이스를 관리\n",
    "     - ex) 매우 깊은 층을 갖는 심층심경망 네트워크 구현시 각 층마다 변수를 정의하는 데 따른 불편함을 해결 \n",
    "     - 코드 모듈화를 더 쉽게할 수 있다는 이점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "weight1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
    "bias1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "weight2 = tf.Variable(tf.random_normal([2, 2]), name='weight2')\n",
    "bias2 = tf.Variable(tf.random_normal([2]), name='bias2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "with tf.variable_scope(\"layer1\", reuse=tf.AUTO_REUSE):\n",
    "    weight = tf.get_variable(\"weight\", shape=[2,2], initializer = tf.random_normal_initializer)\n",
    "    bias = tf.get_variable(\"bias\", shape=[2], initializer = tf.random_normal_initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fetches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 그래프 상에 정의된 작업 하나 이상의 작업 실행 결과 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([21.], dtype=float32), array([7.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "input1 = tf.constant([3.0])\n",
    "input2 = tf.constant([2.0])\n",
    "input3 = tf.constant([5.0])\n",
    "intermed = tf.add(input2, input3)\n",
    "mul = tf.multiply(input1, intermed)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  result = sess.run([mul, intermed])\n",
    "  print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 실행 시점에 정의된 연산 그래프 상으로 텐서 값을 제공하는 매커니즘\n",
    " - tf.placeholder를 이용 텐서(데이터)가 연산 그래프에 입력될 입력 공간을 확보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8591132  0.52360415 0.9762316  0.8129378 ]\n",
      " [1.1395944  0.9928186  0.8628385  1.0856487 ]\n",
      " [0.91354823 0.722215   0.99648666 0.7319969 ]\n",
      " [0.64782953 1.1462001  0.49242216 0.8765619 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x1 = tf.placeholder(tf.float32, shape=(4, 4), name='input1')\n",
    "x2 = tf.placeholder(tf.float32, shape=(4, 4), name='input2')\n",
    "y = tf.matmul(x1, x2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  arr = np.random.rand(4, 4)\n",
    "  print(sess.run(y, feed_dict={x1: arr, x2:arr}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization : Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 텐서플로우가 제공하는 텐서보드를 활용하여 연산 그래프를 시각화\n",
    " - 그래프 실행 후 연산 결과 시각화\n",
    " - `tf.summary.FileWriter()` 객체에 연산 그래프와 연산 결과 값을 저장 후 텐서보드로 시각화   \n",
    " - 벡터: `tf.summary.histogram()`, 스칼라: `tf.summary.scalar()`로 시각화할 연산 값 설정\n",
    " - 텐서보드 실행 => 터미널에서 `tensorboard --logdir=\"./logs/xor_log\"` 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9421437 [array([[ 0.29362255, -0.06695224],\n",
      "       [ 0.37609482,  0.24658176]], dtype=float32), array([[-1.4596896],\n",
      "       [-1.3229216]], dtype=float32)]\n",
      "100 0.6927074 [array([[-0.17431533, -0.6067827 ],\n",
      "       [-0.12266006, -0.3554744 ]], dtype=float32), array([[-0.95402765],\n",
      "       [-0.7798554 ]], dtype=float32)]\n",
      "200 0.6898387 [array([[-0.24704939, -0.7858403 ],\n",
      "       [-0.22705707, -0.63807184]], dtype=float32), array([[-0.9466266],\n",
      "       [-0.7832242]], dtype=float32)]\n",
      "300 0.6801559 [array([[-0.3938941 , -1.2522546 ],\n",
      "       [-0.37949684, -1.1800755 ]], dtype=float32), array([[-0.98279226],\n",
      "       [-0.91001225]], dtype=float32)]\n",
      "400 0.6540122 [array([[-0.7031815 , -2.0512307 ],\n",
      "       [-0.67528826, -2.0068717 ]], dtype=float32), array([[-1.041362 ],\n",
      "       [-1.2895248]], dtype=float32)]\n",
      "500 0.6072009 [array([[-1.17161  , -2.9913337],\n",
      "       [-1.1241554, -2.9534662]], dtype=float32), array([[-1.1388128],\n",
      "       [-1.9376578]], dtype=float32)]\n",
      "600 0.55945873 [array([[-1.6573348, -3.9344401],\n",
      "       [-1.5946952, -3.898004 ]], dtype=float32), array([[-1.2507485],\n",
      "       [-2.6481204]], dtype=float32)]\n",
      "700 0.5297441 [array([[-2.0785484, -4.7100077],\n",
      "       [-2.0055997, -4.6739507]], dtype=float32), array([[-1.3345788],\n",
      "       [-3.2442448]], dtype=float32)]\n",
      "800 0.5132086 [array([[-2.430013, -5.310916],\n",
      "       [-2.349743, -5.274917]], dtype=float32), array([[-1.3864908],\n",
      "       [-3.7100832]], dtype=float32)]\n",
      "900 0.50349724 [array([[-2.7235622, -5.788258 ],\n",
      "       [-2.6379132, -5.752196 ]], dtype=float32), array([[-1.417432 ],\n",
      "       [-4.0812144]], dtype=float32)]\n",
      "1000 0.4973487 [array([[-2.9721045, -6.1816354],\n",
      "       [-2.8823972, -6.145464 ]], dtype=float32), array([[-1.435775],\n",
      "       [-4.387555]], dtype=float32)]\n",
      "1100 0.4931992 [array([[-3.1861289, -6.5161066],\n",
      "       [-3.0932806, -6.479819 ]], dtype=float32), array([[-1.4462494],\n",
      "       [-4.648415 ]], dtype=float32)]\n",
      "1200 0.49025393 [array([[-3.373422 , -6.807532 ],\n",
      "       [-3.2780824, -6.7711334]], dtype=float32), array([[-1.4514904],\n",
      "       [-4.876072 ]], dtype=float32)]\n",
      "1300 0.48807865 [array([[-3.5396483, -7.0663323],\n",
      "       [-3.4422913, -7.029831 ]], dtype=float32), array([[-1.4530404],\n",
      "       [-5.0785947]], dtype=float32)]\n",
      "1400 0.48642045 [array([[-3.6889582, -7.299642 ],\n",
      "       [-3.5899353, -7.263047 ]], dtype=float32), array([[-1.4518567],\n",
      "       [-5.2615004]], dtype=float32)]\n",
      "1500 0.48512337 [array([[-3.8244345, -7.5125284],\n",
      "       [-3.7240171, -7.4758496]], dtype=float32), array([[-1.4485656],\n",
      "       [-5.4287148]], dtype=float32)]\n",
      "1600 0.48408708 [array([[-3.9484189, -7.7087126],\n",
      "       [-3.8468153, -7.671955 ]], dtype=float32), array([[-1.4435968],\n",
      "       [-5.583099 ]], dtype=float32)]\n",
      "1700 0.48324454 [array([[-4.0627184, -7.890992 ],\n",
      "       [-3.9600942, -7.854171 ]], dtype=float32), array([[-1.4372534],\n",
      "       [-5.726821 ]], dtype=float32)]\n",
      "1800 0.48254895 [array([[-4.1687517, -8.061539 ],\n",
      "       [-4.0652447, -8.024656 ]], dtype=float32), array([[-1.4297595],\n",
      "       [-5.861549 ]], dtype=float32)]\n",
      "1900 0.48196718 [array([[-4.2676525, -8.2220545],\n",
      "       [-4.163369 , -8.185111 ]], dtype=float32), array([[-1.4212809],\n",
      "       [-5.9885955]], dtype=float32)]\n",
      "2000 0.48147535 [array([[-4.360339 , -8.373902 ],\n",
      "       [-4.2553706, -8.336915 ]], dtype=float32), array([[-1.4119444],\n",
      "       [-6.109011 ]], dtype=float32)]\n",
      "2100 0.4810553 [array([[-4.447563 , -8.5182   ],\n",
      "       [-4.3419867, -8.481172 ]], dtype=float32), array([[-1.4018495],\n",
      "       [-6.2236505]], dtype=float32)]\n",
      "2200 0.48069364 [array([[-4.52995  , -8.655857 ],\n",
      "       [-4.4238286, -8.618793 ]], dtype=float32), array([[-1.3910738],\n",
      "       [-6.333218 ]], dtype=float32)]\n",
      "2300 0.48037976 [array([[-4.6080246, -8.7876425],\n",
      "       [-4.501412 , -8.750542 ]], dtype=float32), array([[-1.3796793],\n",
      "       [-6.4382977]], dtype=float32)]\n",
      "2400 0.4801055 [array([[-4.6822248, -8.914195 ],\n",
      "       [-4.57517  , -8.877059 ]], dtype=float32), array([[-1.3677173],\n",
      "       [-6.539384 ]], dtype=float32)]\n",
      "2500 0.47986442 [array([[-4.75293 , -9.036063],\n",
      "       [-4.645472, -8.998901]], dtype=float32), array([[-1.3552277],\n",
      "       [-6.636896 ]], dtype=float32)]\n",
      "2600 0.4796514 [array([[-4.820464 , -9.153716 ],\n",
      "       [-4.7126384, -9.1165285]], dtype=float32), array([[-1.3422443],\n",
      "       [-6.731193 ]], dtype=float32)]\n",
      "2700 0.47946215 [array([[-4.885106 , -9.267558 ],\n",
      "       [-4.7769427, -9.230347 ]], dtype=float32), array([[-1.3287935],\n",
      "       [-6.8225875]], dtype=float32)]\n",
      "2800 0.47929323 [array([[-4.9470987, -9.377944 ],\n",
      "       [-4.838625 , -9.340707 ]], dtype=float32), array([[-1.3148977],\n",
      "       [-6.9113474]], dtype=float32)]\n",
      "2900 0.479142 [array([[-5.0066533, -9.485178 ],\n",
      "       [-4.897894 , -9.447919 ]], dtype=float32), array([[-1.3005751],\n",
      "       [-6.997709 ]], dtype=float32)]\n",
      "3000 0.479006 [array([[-5.063961, -9.589533],\n",
      "       [-4.954937, -9.552253]], dtype=float32), array([[-1.2858407],\n",
      "       [-7.0818806]], dtype=float32)]\n",
      "3100 0.4788832 [array([[-5.119185, -9.691246],\n",
      "       [-5.009916, -9.653948]], dtype=float32), array([[-1.2707071],\n",
      "       [-7.1640444]], dtype=float32)]\n",
      "3200 0.47877207 [array([[-5.1724696, -9.790533 ],\n",
      "       [-5.0629745, -9.753216 ]], dtype=float32), array([[-1.2551824],\n",
      "       [-7.2443633]], dtype=float32)]\n",
      "3300 0.47867113 [array([[-5.223949 , -9.887579 ],\n",
      "       [-5.1142416, -9.850246 ]], dtype=float32), array([[-1.2392745],\n",
      "       [-7.322983 ]], dtype=float32)]\n",
      "3400 0.4785794 [array([[-5.2737365, -9.982557 ],\n",
      "       [-5.1638327, -9.9452095]], dtype=float32), array([[-1.2229897],\n",
      "       [-7.4000335]], dtype=float32)]\n",
      "3500 0.47849554 [array([[ -5.321937 , -10.075621 ],\n",
      "       [ -5.2118483, -10.038258 ]], dtype=float32), array([[-1.2063318],\n",
      "       [-7.475633 ]], dtype=float32)]\n",
      "3600 0.47841883 [array([[ -5.3686447, -10.1669035],\n",
      "       [ -5.258382 , -10.129529 ]], dtype=float32), array([[-1.1893033],\n",
      "       [-7.5498857]], dtype=float32)]\n",
      "3700 0.4783485 [array([[ -5.413942, -10.256535],\n",
      "       [ -5.303518, -10.219148]], dtype=float32), array([[-1.1719058],\n",
      "       [-7.622887 ]], dtype=float32)]\n",
      "3800 0.478284 [array([[ -5.4579062, -10.344624 ],\n",
      "       [ -5.3473287, -10.307227 ]], dtype=float32), array([[-1.1541393],\n",
      "       [-7.694724 ]], dtype=float32)]\n",
      "3900 0.47822452 [array([[ -5.5006056, -10.431275 ],\n",
      "       [ -5.3898835, -10.393873 ]], dtype=float32), array([[-1.136003 ],\n",
      "       [-7.7654743]], dtype=float32)]\n",
      "4000 0.4781698 [array([[ -5.5420995, -10.516585 ],\n",
      "       [ -5.4312434, -10.479173 ]], dtype=float32), array([[-1.117495 ],\n",
      "       [-7.8352113]], dtype=float32)]\n",
      "4100 0.47811922 [array([[ -5.5824466, -10.6006365],\n",
      "       [ -5.471462 , -10.563215 ]], dtype=float32), array([[-1.0986122],\n",
      "       [-7.9040008]], dtype=float32)]\n",
      "4200 0.47807243 [array([[ -5.621695, -10.683509],\n",
      "       [ -5.510591, -10.64608 ]], dtype=float32), array([[-1.0793508],\n",
      "       [-7.971902 ]], dtype=float32)]\n",
      "4300 0.47802913 [array([[ -5.659892 , -10.765278 ],\n",
      "       [ -5.5486736, -10.727839 ]], dtype=float32), array([[-1.0597061],\n",
      "       [-8.038971 ]], dtype=float32)]\n",
      "4400 0.47798896 [array([[ -5.697078 , -10.8460045],\n",
      "       [ -5.585751 , -10.8085575]], dtype=float32), array([[-1.039672],\n",
      "       [-8.105258]], dtype=float32)]\n",
      "4500 0.4779517 [array([[ -5.7332897, -10.925752 ],\n",
      "       [ -5.621862 , -10.888298 ]], dtype=float32), array([[-1.0192416],\n",
      "       [-8.170813 ]], dtype=float32)]\n",
      "4600 0.47791705 [array([[ -5.7685604, -11.004578 ],\n",
      "       [ -5.657035 , -10.967117 ]], dtype=float32), array([[-0.99840856],\n",
      "       [-8.235674  ]], dtype=float32)]\n",
      "4700 0.47788477 [array([[ -5.8029203, -11.082534 ],\n",
      "       [ -5.6913023, -11.045069 ]], dtype=float32), array([[-0.97716326],\n",
      "       [-8.299885  ]], dtype=float32)]\n",
      "4800 0.4778547 [array([[ -5.8363953, -11.159671 ],\n",
      "       [ -5.7246895, -11.122199 ]], dtype=float32), array([[-0.955496],\n",
      "       [-8.363483]], dtype=float32)]\n",
      "4900 0.47782665 [array([[ -5.8690085, -11.236032 ],\n",
      "       [ -5.757219 , -11.198553 ]], dtype=float32), array([[-0.9333962],\n",
      "       [-8.426502 ]], dtype=float32)]\n",
      "5000 0.4778005 [array([[ -5.900781, -11.311658],\n",
      "       [ -5.788912, -11.274174]], dtype=float32), array([[-0.9108518],\n",
      "       [-8.488975 ]], dtype=float32)]\n",
      "5100 0.47777605 [array([[ -5.9317303, -11.38659  ],\n",
      "       [ -5.819785 , -11.3491   ]], dtype=float32), array([[-0.88784987],\n",
      "       [-8.55093   ]], dtype=float32)]\n",
      "5200 0.4777532 [array([[ -5.96187  , -11.460863 ],\n",
      "       [ -5.8498526, -11.42337  ]], dtype=float32), array([[-0.86437577],\n",
      "       [-8.612396  ]], dtype=float32)]\n",
      "5300 0.47773182 [array([[ -5.991213 , -11.534511 ],\n",
      "       [ -5.8791285, -11.497013 ]], dtype=float32), array([[-0.8404138],\n",
      "       [-8.6734   ]], dtype=float32)]\n",
      "5400 0.47771177 [array([[ -6.0197706, -11.607566 ],\n",
      "       [ -5.9076204, -11.5700655]], dtype=float32), array([[-0.8159465],\n",
      "       [-8.733964 ]], dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500 0.47769302 [array([[ -6.047548 , -11.6800585],\n",
      "       [ -5.935335 , -11.642555 ]], dtype=float32), array([[-0.7909548],\n",
      "       [-8.794115 ]], dtype=float32)]\n",
      "5600 0.47767544 [array([[ -6.0745487, -11.752015 ],\n",
      "       [ -5.9622765, -11.714508 ]], dtype=float32), array([[-0.7654178],\n",
      "       [-8.853871 ]], dtype=float32)]\n",
      "5700 0.47765887 [array([[ -6.100775 , -11.823464 ],\n",
      "       [ -5.988446 , -11.7859535]], dtype=float32), array([[-0.73931247],\n",
      "       [-8.913251  ]], dtype=float32)]\n",
      "5800 0.47764343 [array([[ -6.1262245, -11.894427 ],\n",
      "       [ -6.013842 , -11.856913 ]], dtype=float32), array([[-0.7126138],\n",
      "       [-8.972277 ]], dtype=float32)]\n",
      "5900 0.47762877 [array([[ -6.1508927, -11.964928 ],\n",
      "       [ -6.0384593, -11.927409 ]], dtype=float32), array([[-0.68529326],\n",
      "       [-9.030967  ]], dtype=float32)]\n",
      "6000 0.47761512 [array([[ -6.1747746, -12.03499  ],\n",
      "       [ -6.062292 , -11.997468 ]], dtype=float32), array([[-0.6573206],\n",
      "       [-9.089336 ]], dtype=float32)]\n",
      "6100 0.47760224 [array([[ -6.1978536, -12.1046295],\n",
      "       [ -6.0853257, -12.067104 ]], dtype=float32), array([[-0.6286621],\n",
      "       [-9.147399 ]], dtype=float32)]\n",
      "6200 0.47759014 [array([[ -6.2201166, -12.173868 ],\n",
      "       [ -6.107545 , -12.136342 ]], dtype=float32), array([[-0.59928  ],\n",
      "       [-9.2051735]], dtype=float32)]\n",
      "6300 0.47757867 [array([[ -6.241545, -12.242724],\n",
      "       [ -6.128932, -12.205196]], dtype=float32), array([[-0.5691328],\n",
      "       [-9.262674 ]], dtype=float32)]\n",
      "6400 0.47756788 [array([[ -6.262113 , -12.311216 ],\n",
      "       [ -6.1494613, -12.273685 ]], dtype=float32), array([[-0.53817403],\n",
      "       [-9.319907  ]], dtype=float32)]\n",
      "6500 0.47755775 [array([[ -6.281794, -12.379356],\n",
      "       [ -6.169105, -12.341825]], dtype=float32), array([[-0.506352],\n",
      "       [-9.376896]], dtype=float32)]\n",
      "6600 0.47754818 [array([[ -6.30055 , -12.447163],\n",
      "       [ -6.187827, -12.409629]], dtype=float32), array([[-0.473609],\n",
      "       [-9.433644]], dtype=float32)]\n",
      "6700 0.47753912 [array([[ -6.3183393, -12.5146475],\n",
      "       [ -6.2055845, -12.477112 ]], dtype=float32), array([[-0.43987963],\n",
      "       [-9.490173  ]], dtype=float32)]\n",
      "6800 0.47753066 [array([[ -6.33511  , -12.581828 ],\n",
      "       [ -6.2223268, -12.54429  ]], dtype=float32), array([[-0.40508997],\n",
      "       [-9.546483  ]], dtype=float32)]\n",
      "6900 0.47752258 [array([[ -6.350805, -12.648714],\n",
      "       [ -6.237994, -12.611174]], dtype=float32), array([[-0.36915642],\n",
      "       [-9.602589  ]], dtype=float32)]\n",
      "7000 0.47751498 [array([[ -6.3653483, -12.715319 ],\n",
      "       [ -6.252513 , -12.677777 ]], dtype=float32), array([[-0.33198297],\n",
      "       [-9.658504  ]], dtype=float32)]\n",
      "7100 0.47750774 [array([[ -6.37866  , -12.781655 ],\n",
      "       [ -6.2658005, -12.744112 ]], dtype=float32), array([[-0.2934596],\n",
      "       [-9.714237 ]], dtype=float32)]\n",
      "7200 0.47750092 [array([[ -6.390635 , -12.847735 ],\n",
      "       [ -6.2777543, -12.810191 ]], dtype=float32), array([[-0.25345874],\n",
      "       [-9.769792  ]], dtype=float32)]\n",
      "7300 0.47749448 [array([[ -6.40115 , -12.913562],\n",
      "       [ -6.288252, -12.876017]], dtype=float32), array([[-0.21183197],\n",
      "       [-9.825183  ]], dtype=float32)]\n",
      "7400 0.47748834 [array([[ -6.410059, -12.979158],\n",
      "       [ -6.297147, -12.941611]], dtype=float32), array([[-0.16840436],\n",
      "       [-9.88043   ]], dtype=float32)]\n",
      "7500 0.4774825 [array([[ -6.4171815, -13.044522 ],\n",
      "       [ -6.3042574, -13.006974 ]], dtype=float32), array([[-0.12296817],\n",
      "       [-9.93552   ]], dtype=float32)]\n",
      "7600 0.47747692 [array([[ -6.4222946, -13.109669 ],\n",
      "       [ -6.30936  , -13.072121 ]], dtype=float32), array([[-0.07527406],\n",
      "       [-9.990487  ]], dtype=float32)]\n",
      "7700 0.4774716 [array([[ -6.4251184, -13.174609 ],\n",
      "       [ -6.312181 , -13.13706  ]], dtype=float32), array([[ -0.02501857],\n",
      "       [-10.045328  ]], dtype=float32)]\n",
      "7800 0.4774665 [array([[ -6.425306, -13.239351],\n",
      "       [ -6.312369, -13.2018  ]], dtype=float32), array([[  0.02817266],\n",
      "       [-10.100051  ]], dtype=float32)]\n",
      "7900 0.47746164 [array([[ -6.422406 , -13.303903 ],\n",
      "       [ -6.3094754, -13.266351 ]], dtype=float32), array([[  0.08476954],\n",
      "       [-10.154676  ]], dtype=float32)]\n",
      "8000 0.47745687 [array([[ -6.4158297, -13.368274 ],\n",
      "       [ -6.302909 , -13.33072  ]], dtype=float32), array([[  0.14537363],\n",
      "       [-10.209223  ]], dtype=float32)]\n",
      "8100 0.47745225 [array([[ -6.404781 , -13.432475 ],\n",
      "       [ -6.2918735, -13.394921 ]], dtype=float32), array([[  0.21077392],\n",
      "       [-10.263678  ]], dtype=float32)]\n",
      "8200 0.4774477 [array([[ -6.3881564, -13.496513 ],\n",
      "       [ -6.2752757, -13.458959 ]], dtype=float32), array([[  0.28203544],\n",
      "       [-10.318096  ]], dtype=float32)]\n",
      "8300 0.477443 [array([[ -6.364371 , -13.560397 ],\n",
      "       [ -6.25153  , -13.5228405]], dtype=float32), array([[  0.36064836],\n",
      "       [-10.372456  ]], dtype=float32)]\n",
      "8400 0.47743818 [array([[ -6.3310275, -13.6241455],\n",
      "       [ -6.2182436, -13.586588 ]], dtype=float32), array([[  0.44879636],\n",
      "       [-10.426816  ]], dtype=float32)]\n",
      "8500 0.47743288 [array([[ -6.284266, -13.687774],\n",
      "       [ -6.17157 , -13.650216]], dtype=float32), array([[  0.5498788],\n",
      "       [-10.481271 ]], dtype=float32)]\n",
      "8600 0.47742656 [array([[ -6.2172956, -13.75129  ],\n",
      "       [ -6.104726 , -13.713732 ]], dtype=float32), array([[  0.669651],\n",
      "       [-10.535844]], dtype=float32)]\n",
      "8700 0.4774176 [array([[ -6.11646 , -13.814711],\n",
      "       [ -6.004094, -13.777151]], dtype=float32), array([[  0.81915253],\n",
      "       [-10.590683  ]], dtype=float32)]\n",
      "8800 0.47740078 [array([[ -5.9475803, -13.87813  ],\n",
      "       [ -5.8355894, -13.84057  ]], dtype=float32), array([[  1.0244431],\n",
      "       [-10.646097 ]], dtype=float32)]\n",
      "8900 0.4773351 [array([[ -5.574147 , -13.941577 ],\n",
      "       [ -5.4631643, -13.9040165]], dtype=float32), array([[  1.3809539],\n",
      "       [-10.703098 ]], dtype=float32)]\n",
      "9000 0.3413502 [array([[ -2.272992 , -14.005183 ],\n",
      "       [ -2.1675246, -13.96749  ]], dtype=float32), array([[  4.175753],\n",
      "       [-10.805031]], dtype=float32)]\n",
      "9100 0.04989261 [array([[ -3.2292628, -14.041091 ],\n",
      "       [ -3.2234437, -14.002501 ]], dtype=float32), array([[  8.334928],\n",
      "       [-11.824973]], dtype=float32)]\n",
      "9200 0.023050766 [array([[ -3.7671585, -14.068204 ],\n",
      "       [ -3.7615159, -14.029397 ]], dtype=float32), array([[  9.681979],\n",
      "       [-12.804358]], dtype=float32)]\n",
      "9300 0.014601024 [array([[ -4.060384 , -14.091892 ],\n",
      "       [ -4.0548067, -14.05291  ]], dtype=float32), array([[ 10.468106],\n",
      "       [-13.472974]], dtype=float32)]\n",
      "9400 0.010508081 [array([[ -4.2622495, -14.112886 ],\n",
      "       [ -4.25668  , -14.073757 ]], dtype=float32), array([[ 11.034479],\n",
      "       [-13.982508]], dtype=float32)]\n",
      "9500 0.008104172 [array([[ -4.4166007, -14.13188  ],\n",
      "       [ -4.41102  , -14.092624 ]], dtype=float32), array([[ 11.482853],\n",
      "       [-14.397963]], dtype=float32)]\n",
      "9600 0.006527243 [array([[ -4.541968 , -14.149342 ],\n",
      "       [ -4.5363708, -14.109972 ]], dtype=float32), array([[ 11.857489],\n",
      "       [-14.751523]], dtype=float32)]\n",
      "9700 0.005415744 [array([[ -4.6478796, -14.165601 ],\n",
      "       [ -4.6422634, -14.126128 ]], dtype=float32), array([[ 12.181675],\n",
      "       [-15.061356]], dtype=float32)]\n",
      "9800 0.0045916038 [array([[ -4.739865, -14.18089 ],\n",
      "       [ -4.734226, -14.141321]], dtype=float32), array([[ 12.469183],\n",
      "       [-15.33867 ]], dtype=float32)]\n",
      "9900 0.0039572166 [array([[ -4.8214116, -14.195382 ],\n",
      "       [ -4.8157525, -14.155726 ]], dtype=float32), array([[ 12.728854 ],\n",
      "       [-15.5908985]], dtype=float32)]\n",
      "10000 0.0034545755 [array([[ -4.894857, -14.209208],\n",
      "       [ -4.889176, -14.169469]], dtype=float32), array([[ 12.96669 ],\n",
      "       [-15.823202]], dtype=float32)]\n",
      "\n",
      "Hypothesis:  [[2.5910439e-04]\n",
      " [9.9717808e-01]\n",
      " [9.9715567e-01]\n",
      " [7.8538600e-03]] \n",
      "Correct:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "x_data = [[0, 0],\n",
    "          [0, 1],\n",
    "          [1, 0],\n",
    "          [1, 1]]\n",
    "y_data = [[0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [0]]\n",
    "x_data = np.array(x_data, dtype=np.float32)\n",
    "y_data = np.array(y_data, dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2], name='x-input')\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name='y-input')\n",
    "\n",
    "with tf.name_scope(\"layer1\"):\n",
    "    W1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
    "    b1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "    layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "    w1_hist = tf.summary.histogram(\"weights1\", W1)\n",
    "    b1_hist = tf.summary.histogram(\"biases1\", b1)\n",
    "    layer1_hist = tf.summary.histogram(\"layer1\", layer1)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"layer2\"):\n",
    "    W2 = tf.Variable(tf.random_normal([2, 1]), name='weight2')\n",
    "    b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "    hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "    w2_hist = tf.summary.histogram(\"weights2\", W2)\n",
    "    b2_hist = tf.summary.histogram(\"biases2\", b2)\n",
    "    hypothesis_hist = tf.summary.histogram(\"hypothesis\", hypothesis)\n",
    "\n",
    "# cost/loss function\n",
    "with tf.name_scope(\"cost\"):\n",
    "    cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *\n",
    "                           tf.log(1 - hypothesis))\n",
    "    cost_summ = tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "accuracy_summ = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # tensorboard --logdir=./logs/xor_logs\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(\"./logs/xor_log\")\n",
    "    writer.add_graph(sess.graph)  # Show the graph\n",
    "\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        summary, _ = sess.run([merged_summary, train], feed_dict={X: x_data, Y: y_data})\n",
    "        writer.add_summary(summary, global_step=step)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={\n",
    "                  X: x_data, Y: y_data}), sess.run([W1, W2]))\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tensorboard --logdir='./logs/xor_log'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
