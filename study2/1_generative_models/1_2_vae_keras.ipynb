{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-2 Variational AutoEncoder\n",
    "\n",
    "<img src=\"./img/vae.png\" alt=\"variationalautoencoder\" width=\"500\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_DIR = \"../generated_output/VAE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0002\n",
    "EPOCHS = 5\n",
    "STEPS_PER_EPOCH = 469\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIM = 784\n",
    "LATENT_DIM = 10\n",
    "ENDOCER_HIDDEN_DIM = [256]\n",
    "DECODER_HIDDEN_DIM = [256]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/vae_recloss.png\" alt=\"vae_recloss\" width=\"400\" align=\"top\"/>\n",
    "<img src=\"./img/vae_regloss.png\" alt=\"vae_regloss\" width=\"450\" align=\"top\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE():\n",
    "     \n",
    "    def __init__(self, image_dim=IMAGE_DIM, latent_dim=LATENT_DIM, encoder_hidden_dim=ENDOCER_HIDDEN_DIM, decoder_hidden_dim=DECODER_HIDDEN_DIM):\n",
    "        self.image_dim = image_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder_hidden_dim = encoder_hidden_dim\n",
    "        self.decoder_hidden_dim = decoder_hidden_dim\n",
    "\n",
    "    def _encoder_model(self, feature):\n",
    "        with tf.variable_scope('encoder', reuse=tf.AUTO_REUSE):\n",
    "            net = feature\n",
    "            for units in self.encoder_hidden_dim:\n",
    "                net = tf.layers.Dense(units, activation=tf.nn.relu, kernel_initializer=tf.initializers.he_normal())(net)\n",
    "            latent_mean = tf.layers.Dense(self.latent_dim, kernel_initializer=tf.initializers.he_normal())(net)\n",
    "            latent_log_var = tf.layers.Dense(self.latent_dim, kernel_initializer=tf.initializers.he_normal())(net)\n",
    "            return latent_mean, latent_log_var\n",
    "\n",
    "    def _sampler_model(self, args):\n",
    "        latent_mean, latent_log_var = args\n",
    "        with tf.variable_scope('sampler', reuse=tf.AUTO_REUSE):\n",
    "            snd_sample = tf.random_normal(tf.shape(latent_log_var), dtype=tf.float32, mean=0., stddev=1.0)\n",
    "            latent_std = tf.exp(latent_log_var / 2)\n",
    "            latent = latent_mean + latent_std * snd_sample\n",
    "            return latent\n",
    "\n",
    "    def _decoder_model(self, feature):\n",
    "        with tf.variable_scope('decoder', reuse=tf.AUTO_REUSE):\n",
    "            net = feature\n",
    "            for units in self.decoder_hidden_dim:\n",
    "                net = tf.layers.Dense(units, activation=tf.nn.relu, kernel_initializer=tf.initializers.he_normal())(net)\n",
    "            recon = tf.layers.Dense(self.image_dim, activation=tf.nn.sigmoid, kernel_initializer=tf.initializers.he_normal())(net)\n",
    "            return recon\n",
    "   \n",
    "    def _vae_loss(self, inputs, outputs, latent_mean, latent_log_var):\n",
    "        def __vae_loss(x,y):\n",
    "            rec_loss = tf.reduce_sum(tf.keras.backend.binary_crossentropy(inputs, outputs), 1)\n",
    "            reg_loss = -0.5 * tf.reduce_sum(1 + latent_log_var - tf.square(latent_mean) - tf.exp(latent_log_var), 1)\n",
    "            return tf.reduce_mean(rec_loss + reg_loss)\n",
    "        return __vae_loss\n",
    "\n",
    "    def _set_model(self):\n",
    "        inputs = tf.keras.Input(shape=[self.image_dim])\n",
    "        latent_mean, latent_log_var = self._encoder_model(inputs)\n",
    "        sample = tf.keras.layers.Lambda(self._sampler_model)([latent_mean, latent_log_var])\n",
    "        outputs = self._decoder_model(sample)\n",
    "        self.model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "        self.vae_loss = self._vae_loss(inputs, outputs, latent_mean, latent_log_var)\n",
    "\n",
    "    def fit(self, x, y, learning_rate, epochs, steps_per_epoch, ckpt_dir):\n",
    "        self.learning_rate = learning_rate\n",
    "        if not os.path.exists(os.path.dirname(ckpt_dir)):\n",
    "            os.makedirs(os.path.dirname(ckpt_dir))\n",
    "        self._set_model()\n",
    "        self.model.compile(optimizer=tf.keras.optimizers.Adam(lr=self.learning_rate), loss=self.vae_loss)\n",
    "        self.model.summary()\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(ckpt_dir+'/cp-{epoch:04d}.ckpt', verbose=1, period=1, save_weights_only=True)\n",
    "        tb_callback = tf.keras.callbacks.TensorBoard(log_dir=ckpt_dir+'/Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "        self.model.fit(x, y, epochs=epochs, steps_per_epoch=steps_per_epoch, callbacks=[cp_callback, tb_callback])\n",
    "\n",
    "    def load_weights(self, ckpt_dir):\n",
    "        self._set_model()\n",
    "        self.model.load_weights(tf.train.latest_checkpoint(ckpt_dir))\n",
    "\n",
    "    def predict(self, features):\n",
    "        self._set_model()\n",
    "        return self.model.predict(features)\n",
    "\n",
    "    def batch(self, features, batch_size, is_training):\n",
    "        self.batch_size=batch_size\n",
    "        if is_training == True:\n",
    "            count = None\n",
    "        else:\n",
    "            count = 1\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((features, features))\n",
    "        batch_dataset = dataset.shuffle(features.shape[0]).repeat(count=count).batch(self.batch_size)\n",
    "        return batch_dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features, batch_size=BATCH_SIZE, learning_rate=LEARNING_RATE, epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH, ckpt_dir=CKPT_DIR):\n",
    "    vae_model = VAE()\n",
    "    batch_x, batch_y = vae_model.batch(features, batch_size, is_training=True)\n",
    "    vae_model.fit(batch_x, batch_y, learning_rate, epochs, steps_per_epoch, ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(features):\n",
    "    features = np.expand_dims(features, axis=0)\n",
    "    vae_model = VAE()\n",
    "    vae_model.load_weights(CKPT_DIR)\n",
    "    return vae_model.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_plot(true, recon):\n",
    "    fig = plt.figure(figsize=(6, 3))\n",
    "    gs = gridspec.GridSpec(1, 2)\n",
    "    gs.update(wspace=0.05)\n",
    "    plt.subplot(gs[0])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(true.reshape([28, 28]), cmap = 'gray_r')\n",
    "    plt.subplot(gs[1])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(recon.reshape([28, 28]), cmap = 'gray_r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "x_train = x_train.reshape([-1, IMAGE_DIM]).astype(np.float32)\n",
    "x_test = x_test.reshape([-1, IMAGE_DIM]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    j = np.random.randint(0,9999)\n",
    "    image_plot(x_test[j], predict(x_test[j]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
