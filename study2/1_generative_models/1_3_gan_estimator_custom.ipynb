{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = '../generated_output/GAN/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "TRAINING_STEPS = 30000\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIM = 784\n",
    "NOISE_DIM = 100\n",
    "GEN_HIDDEN_DIM = [256]\n",
    "DISC_HIDDEN_DIM = [256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN():\n",
    "\n",
    "    def __init__(self, image_dim=IMAGE_DIM, noise_dim=NOISE_DIM, gen_hidden_dim=GEN_HIDDEN_DIM, disc_hidden_dim=DISC_HIDDEN_DIM):\n",
    "        self.image_dim = image_dim\n",
    "        self.noise_dim = noise_dim\n",
    "        self.gen_hidden_dim = gen_hidden_dim\n",
    "        self.disc_hidden_dim = disc_hidden_dim\n",
    "    \n",
    "    def _disc_model(self, features):\n",
    "        with tf.variable_scope('discriminator', reuse=tf.AUTO_REUSE):\n",
    "            net = features\n",
    "            for units in self.disc_hidden_dim:\n",
    "                net = tf.layers.dense(net, units=units, activation=tf.nn.relu, kernel_initializer=tf.initializers.he_normal())\n",
    "            net = tf.layers.dense(net, 1, activation=tf.nn.sigmoid, kernel_initializer=tf.initializers.he_normal())\n",
    "            return net\n",
    "\n",
    "    def _gen_model(self, features):\n",
    "        with tf.variable_scope('generator', reuse=tf.AUTO_REUSE):\n",
    "            net = features\n",
    "            for units in self.gen_hidden_dim:\n",
    "                net = tf.layers.dense(net, units=units, activation=tf.nn.relu, kernel_initializer=tf.initializers.he_normal())\n",
    "            net = tf.layers.dense(net, self.image_dim, activation=tf.nn.sigmoid, kernel_initializer=tf.initializers.he_normal())\n",
    "            return net\n",
    "\n",
    "    def gan_model_fn(self, features, labels, mode, params):\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            input_noise = features\n",
    "            output_image = self._gen_model(input_noise)\n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=output_image)\n",
    "\n",
    "        assert mode == tf.estimator.ModeKeys.TRAIN\n",
    "        real_image = features\n",
    "        fake_noise = tf.random.uniform(shape=[self.batch_size, self.noise_dim], minval=-1., maxval=1., dtype=tf.float32)\n",
    "        fake_image = self._gen_model(fake_noise)\n",
    "        disc_real = self._disc_model(real_image)\n",
    "        disc_fake = self._disc_model(fake_image)\n",
    "        disc_loss = -tf.reduce_mean(tf.log(disc_real) + tf.log(1. - disc_fake))\n",
    "        gen_loss = -tf.reduce_mean(tf.log(disc_fake))\n",
    "        accuracy = tf.metrics.accuracy(labels=tf.zeros(shape=[self.batch_size], dtype=tf.float32),\n",
    "                                    predictions=tf.cast((disc_fake > 0.5),tf.float32),\n",
    "                                    name='acc_op')\n",
    "        tf.summary.scalar('accuracy', accuracy[1])\n",
    "        tf.summary.scalar('loss_gen', gen_loss)\n",
    "        tf.summary.scalar('loss_disc', disc_loss)\n",
    "        optimizer_disc = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE)\n",
    "        optimizer_gen = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE)\n",
    "        disc_train_op = optimizer_disc.minimize(disc_loss,var_list=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"discriminator\"), global_step=tf.train.get_global_step())\n",
    "        gen_train_op = optimizer_gen.minimize(gen_loss, var_list=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"generator\"), global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=gen_loss + disc_loss, train_op=tf.group(disc_train_op, gen_train_op))\n",
    "\n",
    "    def batch(self, features, batch_size, is_training):\n",
    "        self.batch_size = batch_size\n",
    "        if is_training == True:\n",
    "            count = None\n",
    "        else:\n",
    "            count = 1\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(features)\n",
    "        return dataset.shuffle(features.shape[0]).repeat(count=count).batch(self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_image_plot(estimator, input_fn, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    random_noise = np.random.uniform(-1., 1., size=[1, NOISE_DIM]).astype(np.float32)\n",
    "    random_image = estimator.predict(input_fn=lambda:input_fn(random_noise, is_training=False, batch_size=1))\n",
    "    print(random_image)\n",
    "    for x in random_image:\n",
    "        p = x.reshape([28, 28])\n",
    "        plt.imshow(p, cmap = 'gray_r')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_model = GAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_estimator = tf.estimator.Estimator(\n",
    "    model_fn=gan_model.gan_model_fn,\n",
    "    model_dir=MODEL_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.keras.datasets.mnist.load_data()[0][0] / 255.\n",
    "x_train = x_train.reshape([-1, IMAGE_DIM]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_estimator.train(input_fn=lambda:gan_model.batch(x_train, BATCH_SIZE, is_training=True), steps=TRAINING_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image_plot(gan_estimator, gan_model.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
