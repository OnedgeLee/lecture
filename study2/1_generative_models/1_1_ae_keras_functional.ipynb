{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-1 AutoEncoder\n",
    "\n",
    "<img src=\"./img/ae.png\" alt=\"autoencoder\" width=\"500\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_DIR = \"../generated_output/AE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0002\n",
    "TRAINING_STEPS = 30000\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIM = 784\n",
    "LATENT_DIM = 128\n",
    "ENDOCER_HIDDEN_DIM = [256]\n",
    "DECODER_HIDDEN_DIM = [256]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[batch_size, 784]\n",
    "\n",
    "$\\rightarrow$ Dense(784, 256) $\\rightarrow$ relu $\\rightarrow$ [batch_size, 256]\n",
    "\n",
    "$\\rightarrow$ Dense(256, 128) $\\rightarrow$ sigmoid $\\rightarrow$ [batch_size, 128] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_model(feature, encoder_hidden_dim=ENDOCER_HIDDEN_DIM, latent_dim=LATENT_DIM):\n",
    "    with tf.variable_scope('encoder', reuse=tf.AUTO_REUSE):\n",
    "        net = feature\n",
    "        for units in encoder_hidden_dim:\n",
    "            net = tf.layers.Dense(units, activation=tf.nn.relu, kernel_initializer=tf.initializers.he_normal())(net)\n",
    "        net = tf.layers.Dense(latent_dim, activation=tf.nn.sigmoid, kernel_initializer=tf.initializers.he_normal())(net)\n",
    "        return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[batch_size, 128]\n",
    "\n",
    "$\\rightarrow$ Dense(128, 256) $\\rightarrow$ relu $\\rightarrow$ [batch_size, 256]\n",
    "\n",
    "$\\rightarrow$ Dense(256, 784) $\\rightarrow$ sigmoid $\\rightarrow$ [batch_size, 784] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_model(feature, decoder_hidden_dim=DECODER_HIDDEN_DIM, image_dim=IMAGE_DIM):\n",
    "    with tf.variable_scope('decoder', reuse=tf.AUTO_REUSE):\n",
    "        net = feature\n",
    "        for units in decoder_hidden_dim:\n",
    "            net = tf.layers.Dense(units, activation=tf.nn.relu, kernel_initializer=tf.initializers.he_normal())(net)\n",
    "        net = tf.layers.Dense(image_dim, activation=tf.nn.sigmoid, kernel_initializer=tf.initializers.he_normal())(net)\n",
    "        return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[batch_size, 784]\n",
    "\n",
    "$\\rightarrow$ Dense(784, 256) $\\rightarrow$ relu $\\rightarrow$ [batch_size, 256]\n",
    "\n",
    "$\\rightarrow$ Dense(256, 128) $\\rightarrow$ sigmoid $\\rightarrow$ [batch_size, 128] \n",
    "\n",
    "$\\rightarrow$ Dense(128, 256) $\\rightarrow$ relu $\\rightarrow$ [batch_size, 256]\n",
    "\n",
    "$\\rightarrow$ Dense(256, 784) $\\rightarrow$ sigmoid $\\rightarrow$ [batch_size, 784] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ae_model_fn(input_shape, learning_rate=LEARNING_RATE):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    latents = encoder_model(inputs)\n",
    "    outputs = decoder_model(latents)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
    "              loss=tf.keras.losses.mean_squared_error)    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_input_fn(features, is_training, batch_size):\n",
    "    if is_training == True:\n",
    "        count = None\n",
    "    else:\n",
    "        count = 1\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features, features))\n",
    "    batch_dataset = dataset.shuffle(features.shape[0]).repeat(count=count).batch(batch_size)\n",
    "    return batch_dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features, batch_size=BATCH_SIZE, ckpt_dir=CKPT_DIR):\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "    batch_x, batch_y = data_input_fn(features, is_training=True, batch_size=batch_size)\n",
    "    model = ae_model_fn(features[0].shape)\n",
    "    model.summary()\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(ckpt_dir+'/cp-{epoch:04d}.ckpt', verbose=1, period=1, save_weights_only=True)\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=ckpt_dir+'/Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "    model.fit(x=batch_x,y=batch_y, epochs=5, steps_per_epoch=469, callbacks=[cp_callback, tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(features, ckpt_dir=CKPT_DIR):\n",
    "    features = np.expand_dims(features, axis=0)\n",
    "    model = ae_model_fn(features[0].shape)\n",
    "    model.load_weights(tf.train.latest_checkpoint(ckpt_dir))\n",
    "    return model.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_plot(true, recon):\n",
    "    fig = plt.figure(figsize=(6, 3))\n",
    "    gs = gridspec.GridSpec(1, 2)\n",
    "    gs.update(wspace=0.05)\n",
    "    plt.subplot(gs[0])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(true.reshape([28, 28]), cmap = 'gray_r')\n",
    "    plt.subplot(gs[1])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(recon.reshape([28, 28]), cmap = 'gray_r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "x_train = x_train.reshape([-1, IMAGE_DIM]).astype(np.float32)\n",
    "x_test = x_test.reshape([-1, IMAGE_DIM]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    j = np.random.randint(0,9999)\n",
    "    image_plot(x_test[j], predict(x_test[j]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
