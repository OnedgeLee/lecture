{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-1. MLP (나비야 음계 학습)\n",
    "\n",
    "<img src=\"./img/song.png\" alt=\"song\" width=\"450\" align=\"left\"/>\n",
    "<img src=\"./img/song_mlp.png\" alt=\"song_mlp\" width=\"450\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_DIR = \"../generated_output/MLP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(CKPT_DIR):\n",
    "    os.makedirs(CKPT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = ['g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'd8', 'e8', 'f8', 'g8', 'g8', 'g4',\n",
    "       'g8', 'e8', 'e8', 'e8', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4',\n",
    "       'd8', 'd8', 'd8', 'd8', 'd8', 'e8', 'f4', 'e8', 'e8', 'e8', 'e8', 'e8', 'f8', 'g4',\n",
    "       'g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note2idx = {'c4':0, 'd4':1, 'e4':2, 'f4':3, 'g4':4, 'a4':5, 'b4':6,\n",
    "            'c8':7, 'd8':8, 'e8':9, 'f8':10, 'g8':11, 'a8':12, 'b8':13}\n",
    "\n",
    "idx2note = {0:'c4', 1:'d4', 2:'e4', 3:'f4', 4:'g4', 5:'a4', 6:'b4',\n",
    "            7:'c8', 8:'d8', 9:'e8', 10:'f8', 11:'g8', 12:'a8', 13:'b8'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2dataset(seq, window_size):\n",
    "    dataset = []\n",
    "    for i in range(len(seq)-window_size):\n",
    "        subset = seq[i:(i+window_size+1)]\n",
    "        dataset.append([note2idx[item] for item in subset])\n",
    "    return np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = seq2dataset(seq, window_size = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = dataset[:,0:4]\n",
    "y_train = dataset[:,4]\n",
    "max_idx_value = 13\n",
    "x_train = x_train / float(max_idx_value)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "one_hot_vec_size = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=4, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(one_hot_vec_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=CKPT_DIR+'/Graph', histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=2000, batch_size=10, verbose=1, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_train, y_train)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/one_step.png\" alt=\"one_step\" width=\"500\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_count = 50\n",
    "note_onestep = ['g8', 'e8', 'e4', 'f8']\n",
    "pred_out = model.predict(x_train)\n",
    "for i in range(pred_count):\n",
    "    idx = np.argmax(pred_out[i])\n",
    "    note_onestep.append(idx2note[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/full_song.png\" alt=\"full_song\" width=\"500\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_in = ['g8', 'e8', 'e4', 'f8']\n",
    "note_fullsong = seq_in\n",
    "seq_in = [note2idx[it] / float(max_idx_value) for it in seq_in]\n",
    "for i in range(pred_count):\n",
    "    sample_in = np.array(seq_in)\n",
    "    sample_in = np.reshape(sample_in, (1, 4))\n",
    "    pred_out = model.predict(sample_in)\n",
    "    idx = np.argmax(pred_out)\n",
    "    note_fullsong.append(idx2note[idx])\n",
    "    seq_in.append(idx / float(max_idx_value))\n",
    "    seq_in.pop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/mlp_result.png\" alt=\"mlp_result\" width=\"500\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"one step prediction : \", note_onestep)\n",
    "print(\"full song prediction : \", note_fullsong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21 as m21\n",
    "from writeMIDI import writeMIDI\n",
    "\n",
    "def note2midi(notes, num):    # input : seq_out\n",
    "    n = []\n",
    "    global start\n",
    "    start = 0    # 맨 첫 note의 시작 위치\n",
    "    for i in range(len(notes)):\n",
    "        #print(notes[i][0], notes[i][1])\n",
    "        timing = int(8/int(notes[i][1]))\n",
    "        \n",
    "        if timing == 1: n.append((notes[i][0]+'5',start+i,1,120))\n",
    "        else :\n",
    "            n.append((notes[i][0]+'5',start+i,1*timing,120))\n",
    "            start += 1\n",
    "        \n",
    "        # Output MIDI (Root, Inst., BPM, Notes, File_name)\n",
    "        if not os.path.exists(CKPT_DIR+'/Midi'):\n",
    "            os.makedirs(CKPT_DIR+'/Midi')\n",
    "        writeMIDI('C','piano', 130, n, (CKPT_DIR+'/Midi/MLP_result_%d' % num))\n",
    "        \n",
    "    return print(\"MLP result_%d export complete!\" % num)\n",
    "\n",
    "\n",
    "note2midi(note_onestep, 1)\n",
    "note2midi(note_fullsong, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[MIDI 재생 사이트 링크](https://onlinesequencer.net/import)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
