{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0-1. Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow 2.0 (Google Tensorflow Team)\n",
    "  - Tensorflow 2.0에서는 Keras를 Tensorflow와 보다 강력하게 인테그레이팅 하는 것을 목표로 함\n",
    "  - Estimator은 Tensorflow 2.0에 포함되나, Keras로 작성한 뒤, model_to_estimator()을 이용할 것을 권장\n",
    "  \n",
    "### Keras란?\n",
    "  - 구글의 Francois Chollet 개발 / 유지보수\n",
    "  - 다양한 프레임워크 위에서 수행가능한 고수준 라이브러리 (MXNet, DL4J, Tensorflow, Microsoft Cognitive Toolkit, Theano)\n",
    "  - 현재 Tensorflow에는 tf.keras로 모듈화 되어있으며, 점점 긴밀하게 인테그레이팅하여 내재화 예정\n",
    "\n",
    "### Keras의 사용자 입장에서의 장점\n",
    "  - Model객체를 통하여 간편하고 쉽게 아키텍처 설계 / 학습 및 인퍼런스 수행 가능\n",
    "\n",
    "### Keras의 사용자 입장에서의 단점\n",
    "  - 커스터마이징이 어려움 (특히 loss function)\n",
    "  - 현재 버전(1.12)의 Tensorflow 환경에서는 아직 이질적인 서드파티 라이브러리로서의 느낌이 강함(긴밀도 떨어짐)\n",
    "\n",
    "### Keras를 쓰는 방법\n",
    "  1. Sequential\n",
    "  2. Functional\n",
    "  3. Subclassing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential이란?\n",
    "  - sequential 모델 객체를 먼저 생성한 뒤, 여기에 layers를 붙여나가는 구조\n",
    "  - keras의 모델 구성 방법 중 가장 고수준\n",
    "  - 기본적이고 범용적인 모델에 가까울 경우 이용 용이\n",
    "  - 복잡한 모델에는 적합하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0-1-1. 모델 변수 정의\n",
    "  - 고수준 layers(tf.layers 혹은 tf.keras.layers)의 Dense(FC)층은 output node의 수만으로 정의 가능하기에 아래와 같이 쉽게 모델변수 작성 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_hidden_dim = [512, 128]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0-1-2. 시퀀스 모델 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0-1-3. 모델 레이어 시퀀스 구성\n",
    "[batch_size, 28, 28]\n",
    "\n",
    "$\\rightarrow$ Flatten $\\rightarrow$ [batch_size, 784]\n",
    "\n",
    "$\\rightarrow$ Dense(784, 512) $\\rightarrow$ relu $\\rightarrow$ [batch_size, 512]\n",
    "\n",
    "$\\rightarrow$ Dropout $\\rightarrow$ Dense(512, 128) $\\rightarrow$ relu $\\rightarrow$ [batch_size, 128] \n",
    "\n",
    "$\\rightarrow$ Dropout $\\rightarrow$ Dense(128, 10) $\\rightarrow$ softmax $\\rightarrow$ [batch_size, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Flatten())\n",
    "for units in mnist_hidden_dim:\n",
    "    model.add(tf.keras.layers.Dense(units, activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0-1-4. 시퀀스 구성 완료 후 컴파일\n",
    "  - optimizer : 최적화 방법 지정\n",
    "  - loss : 로스 함수 지정\n",
    "    - \"sparse_categorical_crossentropy\" : one-hot encoding을 하지 않아도 자동으로 해 주는 loss\n",
    "  - metrics : training / evaluating시 판단의 근거로 삼을 메트릭 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.train.AdamOptimizer(1e-3),\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0-1-5. 데이터 추출\n",
    "  - tensorflow.examples.tutorials.mnist는 deprecated\n",
    "  - 많은 예제가 아직 위의 코드를 이용하고 있는데, keras의 데이터추출이 쉽고 편함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0-1-6. 학습\n",
    "  - Sequential 모델 객체의 fit 메서드를 통해 데이터를 배치로 자르고, 셔플링하는 과정까지 한번에 가능\n",
    "  - 그러나, tensorflow.data.Dataset의 적극적 활용을 권장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=5, batch_size=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0-1-7. 평가\n",
    "  - Sequential 모델 객체의 evaluate 메서드를 통해 테스트 데이터셋 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.evaluate(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
